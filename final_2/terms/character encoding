{"batchcomplete":"","query":{"normalized":[{"from":"Character_encoding","to":"Character encoding"}],"pages":{"5295":{"pageid":5295,"ns":0,"title":"Character encoding","revisions":[{"contentformat":"text/x-wiki","contentmodel":"wikitext","*":"In computing, a '''character encoding''' is used to represent a repertoire of [[character (computing)|character]]s by some kind of an [[code|encoding]] system.<ref>Definition from [http://techterms.com/definition/characterencoding The Tech Terms Dictionary] </ref> Depending on the [[abstraction level]] and context, corresponding [[code point]]s and the resulting code space may be regarded as [[bitstream|bit pattern]]s, [[octet (computing)|octets]], natural [[number]]s, electrical [[pulses]], etc. A character encoding is used in [[computation]], [[computer data storage|data storage]], and transmission of textual [[data]]. '''Character set''', '''character map''', '''codeset''' and '''[[code page]]''' are related, but not identical, terms.\n\nEarly character codes associated with the optical or electrical [[Telegraphy|telegraph]] could only represent a subset of the characters used in written languages, sometimes restricted to upper case letters, numerals and some punctuation only. The low cost of digital representation of data in modern computer systems allows more elaborate character codes (such as [[Unicode]]) which represent more of the characters used in many written languages. Character encoding using internationally accepted standards permits worldwide interchange of text in electronic form.\n\n==History==\nEarly binary repertoires include [[Bacon's cipher]], [[Braille]], [[International maritime signal flags]], and the 4-digit encoding of Chinese characters for a [[Chinese telegraph code]] ([[Hans Schjellerup]], 1869). Common examples of character encoding systems include [[Morse code]], the [[Baudot code]], the American Standard Code for Information Interchange ([[ASCII]]) and [[Unicode]].<ref>{{cite web | url=http://blog.smartbear.com/development/ancient-computer-character-code-tables-and-why-theyre-still-relevant/?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+SmartBear+%28SmartBear+Software+Quality+Matters+Blog%29 | title=Ancient Computer Character Code Tables \u2013 and Why They\u2019re Still Relevant | publisher=Smartbear | date=April 17, 2014 | accessdate=29 April 2014 | author=Tom Henderson}}</ref>\n\n[[Morse code]] was introduced in the 1840s and is used to encode each letter of the [[Latin alphabet]], each [[Arabic numeral]], and some other characters via a series of long and short presses of a [[telegraph key]]. Representations of characters encoded using Morse code varied in length.\n\nThe [[Baudot code]], a five-bit encoding, was created by [[\u00c9mile Baudot]] in 1870, patented in 1874, modified by Donald Murray in 1901, and standardized by CCITT as International Telegraph Alphabet No. 2 (ITA2) in 1930.\n\n[[Fieldata]], a six- or seven-bit code, was introduced by the U.S. Army Signal Corps in the late 1950s.\n\n[[IBM]]'s [[Binary-coded decimal#IBM and BCD|Binary Coded Decimal]] ([[BCD (character encoding)|BCD]]) was a six-bit encoding scheme used by IBM in as early as 1959 in its [[IBM 1401|1401]] and [[IBM 1620|1620]] computers, and in its [[IBM 700/7000 series|7000 Series]] (for example, 704, 7040, 709 and 7090 computers), as well as in associated peripherals. BCD extended existing simple four-bit numeric encoding to include alphabetic and special characters, mapping it easily to punch-card encoding which was already in widespread use. It was the precursor to EBCDIC.\n\n[[ASCII]] was introduced in 1963 and is a seven-bit encoding scheme used to encode letters, numerals, symbols, and device [[control code]]s as fixed-length codes using [[integer]]s.\n\n[[IBM]]'s [[EBCDIC|Extended Binary Coded Decimal Interchange Code]] (usually abbreviated as EBCDIC) is an eight-bit encoding scheme developed in 1963.\n\nThe limitations of such sets soon became apparent, and a number of ''ad hoc'' methods were developed to extend them. The need to support more [[writing system]]s for different languages, including the [[CJK characters|CJK]] family of East Asian scripts, required support for a far larger number of characters and demanded a systematic approach to character encoding rather than the previous ad hoc approaches.\n\nIn trying to develop universally interchangeable character encodings, researchers in the 1980s faced the dilemma that on the one hand, it seemed necessary to add more bits to accommodate additional characters, but on the other hand, for the users of the relatively small character set of the Latin alphabet (who still constituted the majority of computer users), those additional bits were a colossal waste of then-scarce and expensive computing resources (as they would always be zeroed out for such users).\n\nThe compromise solution that was eventually found and developed into Unicode was to break the assumption (dating back to telegraph codes) that each character should always directly correspond to a particular sequence of bits. Instead, characters would first be mapped to a universal intermediate representation in the form of abstract numbers called [[code point]]s. Code points would then be represented in a variety of ways and with various default numbers of bits per character (code units) depending on context. To encode code points higher than the length of the code unit, such as above 256 for 8-bit units, the solution was to implement [[variable-width encoding]]s where an escape sequence would signal that subsequent bits should be parsed as a higher code point.\n\n==Terminology==\n[[File:KB Dubeolsik for Old Hangul (NG3).svg|thumb|365x365px]]\n'''Terminology related to code unit:'''\n* A '''''character''''' is a minimal unit of text that has semantic value.\n* A '''''character set''''' is a collection of characters that might be used by multiple languages. \n'''''Example:''''' The Latin character set is used by English and most European languages, though the Greek character set is used only by the Greek language.\n* A '''''coded character set''''' is a character set in which each character corresponds to a unique number.\n* A '''''code point''''' of a coded character set is any legal value in the character set.\n* A '''''code unit''''' is a bit sequence used to encode each character of a repertoire within a given encoding form.\n\n'''Character repertoire (the abstract list of characters):'''\n\nThe character repertoire is an abstract list of more than one million characters found in a wide variety of scripts including ''Latin, Cyrillic, Chinese, Korean, Japanese, Hebrew, and Aramaic''.\n\nOther symbols such as musical notation are also included in the character repertoire. Both the Unicode and [[GB 18030|GB18030]] standards have a character repertoire. As new characters are added to one standard, the other standard also adds those characters, to maintain parity.\n\nThe code unit size is equivalent to the bit measurement for the particular encoding:\n* A code unit in [[US-ASCII]] consists of 7 bits;\n* A code unit in [[UTF-8]], [[EBCDIC]] and [[GB 18030|GB18030]] consists of 8 bits;\n* A code unit in [[UTF-16]] consists of 16 bits;\n* A code unit in [[UTF-32]] consists of 32 bits.\n\n'''''Example of a code unit:''''' Consider a '''''[[String (computer science)|string]]''''' of the letters \"abc\" followed by the '''''[http://www.charbase.com/10400-unicode-deseret-capital-letter-long-i Deseret LONG I]''''', which is represented with '''''two char values'''''. That string contains four characters, four code points, and '''''five code units'''''.\n\nTo express a character in Unicode, the hexadecimal value is prefixed with the string 'U+'. The range of valid code points for the Unicode standard is U+0000 to U+10FFFF, inclusive. These characters are sometimes called the ''[[Plane (Unicode)#Basic Multilingual Plane|Basic Multilingual Plane (BMP)]]''. Characters in the range U+10000 to U+10FFFF are called [http://www.i18nguy.com/surrogates.html supplementary characters].\n\nThe following table shows examples of code point values:\n{| class=\"MsoNormalTable\"\n \n  |\n'''Character'''\n\n  |\n'''Unicode code point'''\n\n  |\n'''Glyph'''\n \n |-\n  |\nLatin A\n\n  |\nU+0041\n\n  |\u0391\n \n |-\n  |\nLatin sharp S\n\n  |\nU+00DF\n\n  |\u00df\n \n |-\n  |\nHan for East\n\n  |\nU+6771\n\n  |\u6771\n \n |-\n  |\nAmpersand\n\n  |\nU+0026\n\n  |&\n |-\n|Inverted exclamation mark\n|U+00A1\n|\u00a1\n|-\n|Section sign\n|U+00A7\n|\u00a7\n|}\n\nA code point is represented by a sequence of code units. The mapping is defined by the encoding. Thus, the number of code units required to represent a code point depends on the encoding:\n* '''''UTF-8''':'' code points map to a sequence of one, two, three or four code units.\n* '''''UTF-16''':''  Code units are twice longer than 8-bit code units. Therefore, any code point with a scalar value less than U+10000 are encoded with a single code unit. Code points with a value U+10000 or higher require two code units each. These pairs of code units have a unique term in UTF-16: [[UTF-16#cite note-Unicode7Ch3s8-5|\"Unicode surrogate pairs\".]]\n* '''''UTF-32''':'' The 32-bit code unit is large enough that every code point is represented as a single code unit.\n* '''''GB18030''':'' Multiple code units per code point are common, because of the small code units. Code points are mapped to one, two, or four code units.<ref>http://docs.oracle.com/javase/tutorial/i18n/text/terminology.html</ref>\n\n=={{anchor|CCS}}Unicode encoding model==\n[[Unicode]] and its parallel standard, the ISO/IEC 10646 [[Universal Character Set]], together constitute a modern, unified character encoding. Rather than mapping characters directly to octets ([[byte]]s), they separately define what characters are available, corresponding natural numbers ([[code point]]s), how those numbers are encoded as a series of fixed-size natural numbers (code units), and finally how those units are encoded as a stream of octets. The purpose of this decomposition is to establish a universal set of characters that can be encoded in a variety of ways.<ref name=utr17>{{cite web |url=http://www.unicode.org/reports/tr17/ |title=Unicode Technical Report #17: Unicode Character Encoding Model |date=2008-11-11 |accessdate=2009-08-08}}</ref> To describe this model correctly requires more precise terms than \"character set\" and \"character encoding.\" The terms used in the modern model follow:<ref name=utr17/>\n\nA '''character repertoire''' is the full set of abstract characters that a system supports. The repertoire may be closed, i.e. no additions are allowed without creating a new standard (as is the case with ASCII and most of the ISO-8859 series), or it may be open, allowing additions (as is the case with Unicode and to a limited extent the [[Windows code page]]s). The characters in a given repertoire reflect decisions that have been made about how to divide writing systems into basic information units. The basic variants of the [[Latin alphabet|Latin]], [[Greek alphabet|Greek]] and [[Cyrillic]] alphabets can be broken down into letters, digits, punctuation, and a few ''special characters'' such as the space, which can all be arranged in simple linear sequences that are displayed in the same order they are read. But even with these alphabets, [[diacritic]]s pose a complication: they can be regarded either as part of a single character containing a letter and diacritic (known as a precomposed character), or as separate characters. The former allows a far simpler text handling system but the latter allows any letter/diacritic combination to be used in text. [[Typographic ligature|Ligatures]] pose similar problems. Other writing systems, such as Arabic and Hebrew, are represented with more complex character repertoires due to the need to accommodate things like bidirectional text and [[glyph]]s that are joined together in different ways for different situations.\n\nA '''coded character set''' (CCS) is a [[function (mathematics)|function]] that maps characters to ''[[code point]]s'' (each code point represents one character). For example, in a given repertoire, the capital letter \"A\" in the Latin alphabet might be represented by the code point 65, the character \"B\" to 66, and so on. Multiple coded character sets may share the same repertoire; for example [[ISO/IEC 8859-1]] and IBM code pages 037 and 500 all cover the same repertoire but map them to different code points.\n\nA '''character encoding form''' (CEF) is the mapping of code points to ''code units'' to facilitate storage in a system that represents numbers as bit sequences of fixed length (i.e. practically any computer system). For example, a system that stores numeric information in 16-bit units can only directly represent code points 0 to 65,535 in each unit, but larger code points (say, 65,536 to 1.4 million) could be represented by using multiple 16-bit units. This correspondence is defined by a CEF.\n\nNext, a '''character encoding scheme''' (CES) is the mapping of code units to a sequence of octets to facilitate storage on an octet-based file system or transmission over an octet-based network. Simple character encoding schemes include [[UTF-8]], [[UTF-16BE]], [[UTF-32BE]], [[UTF-16LE]] or [[UTF-32LE]]; compound character encoding schemes, such as [[UTF-16]], [[UTF-32]] and [[ISO/IEC 2022]], switch between several simple schemes by using [[byte order mark]]s or [[escape sequence]]s; compressing schemes try to minimise the number of bytes used per code unit (such as [[Standard Compression Scheme for Unicode|SCSU]], [[Binary Ordered Compression for Unicode|BOCU]], and [[Punycode]]).\n\nAlthough [[UTF-32BE]] is a simpler CES, most systems working with Unicode use either [[UTF-8]], which is [[backward compatibility|backward compatible]] with fixed-width ASCII and maps Unicode code points to variable-width sequences of octets, or [[UTF-16BE]], which is [[backward compatibility|backward compatible]] with fixed-width UCS-2BE and maps Unicode code points to variable-width sequences of 16-bit words. See [[comparison of Unicode encodings]] for a detailed discussion.\n\nFinally, there may be a '''higher level protocol''' which supplies additional information to select the particular variant of a [[Unicode]] character, particularly where there are regional variants that have been 'unified' in Unicode as the same character. An example is the [[XML]] attribute xml:lang.\n\nThe Unicode model uses the term '''character map''' for historical systems which directly assign a sequence of characters to a sequence of bytes, covering all of CCS, CEF and CES layers.<ref name=\"utr17\" />\n\n== Character sets, maps and code pages ==\nHistorically, the terms \"character encoding\", \"character map\", \"character set\" and \"[[code page]]\" were synonymous in [[computer science]], as the same standard would specify a repertoire of characters and how they were to be encoded into a stream of code units \u2013 usually with a single character per code unit. But now the terms have related but distinct meanings, due to efforts by standards bodies to use precise terminology when writing about and unifying many different encoding systems.<ref name=utr17/> Regardless, the terms are still used interchangeably, with ''character set'' being nearly ubiquitous.\n\nA \"'''code page'''\" usually means a [[byte oriented|byte-oriented]] encoding, but with regard to some suite of encodings (covering different scripts), where many characters share the same [[code point|codes]] in most or all those code pages. Well-known code page suites are \"Windows\" (based on Windows-1252) and \"IBM\"/\"DOS\" (based on [[code page 437]]), see [[Windows code page]] for details. Most, but not all, encodings referred to as code pages are single-byte encodings (but see [[Octet (computing)|octet]] on byte size.)\n\nIBM's Character Data Representation Architecture (CDRA) designates with coded character set identifiers ([[CCSID]]s) and each of which is variously called a \"charset\", \"character set\", \"code page\", or \"CHARMAP\".<ref name=utr17/>\n\nThe term \"code page\" does not occur in Unix or Linux where \"charmap\" is preferred, usually in the larger context of locales.\n\nContrasted to [[#CCS|CCS above]], a \"character encoding\" is a map from abstract characters to [[code word]]s. A \"character set\" in [[HTTP]] (and [[MIME]]) parlance is the same as a character encoding (but not the same as CCS).\n\n\"[[legacy system|Legacy]] encoding\" is a term sometimes used to characterize old character encodings, but with an ambiguity of sense. Most of its use is in the context of [[Unicode|Unicodification]], where it refers to encodings that fail to cover all Unicode code points, or, more generally, using a somewhat different character repertoire: several code points representing one Unicode character,<ref>[http://www.basistech.co.jp/knowledge-center/database/uc-trillium-2.ppt \"Processing database information using Unicode, a case study\"] {{wayback|url=http://www.basistech.co.jp/knowledge-center/database/uc-trillium-2.ppt |date=20060617193918 }}</ref> or versa (see e.g. [[code page 437]]). Some sources refer to an encoding as ''legacy'' only because it preceded Unicode.<ref>{{cite web|url=http://scripts.sil.org/cms/scripts/page.php?site_id=nrsi&item_id=IWS-Chapter03#79e846db|publisher=[[SIL International]]|title=Character set encoding basics|work=Implementing Writing Systems: An introduction|first=Peter|last=Constable|date=2001-06-13|accessdate=2010-03-19}}</ref> All Windows code pages are usually referred to as legacy, both because they antedate Unicode and because they are unable to represent all 2<sup>21</sup> possible Unicode code points.\n\n== Character encoding translation ==\nAs a result of having many character encoding methods in use (and the need for backward compatibility with archived data), many computer programs have been developed to translate data between encoding schemes as a form of data [[transcoding]]. Some of these are cited below.\n\n[[Cross-platform]]:\n* [[Web browser]]s \u2013 most modern web browsers feature automatic character encoding detection. On Firefox 3, for example, see the View/Character Encoding submenu.\n* [[iconv]] \u2013 program and standardized API to convert encodings\n* [[luit]] \u2013 program that converts encoding of input and output to programs running interactively\n* convert_encoding.py \u2013 Python based utility to convert text files between arbitrary encodings and line endings.<ref>[https://github.com/goerz/convert_encoding.py convert_encoding.py]</ref>\n* decodeh.py \u2013 algorithm and module to heuristically guess the encoding of a string.<ref>[http://gizmojo.org/code/decodeh/ Decodeh \u2013 heuristically decode a string or text file] {{wayback|url=http://gizmojo.org/code/decodeh/ |date=20080108123255 }}</ref>\n* [[International Components for Unicode]] \u2013 A set of C and Java libraries to perform charset conversion. uconv can be used from ICU4C.\n* [http://pypi.python.org/pypi/chardet chardet] \u2013 This is a translation of the [[Mozilla]] automatic-encoding-detection code into the Python computer language.\n* The newer versions of the Unix [[file (command)|file]] command attempt to do a basic detection of character encoding (also available on [[Cygwin]]).\n* [http://sourceforge.net/projects/charset charset] - [[C++]] template library with simple interface to convert between C++\\user-defined streams. charset defined many character-sets and allows you to use Unicode formats with support of [[endianness]].\n[[Unix-like]]: \n* cmv \u2013 simple tool for transcoding filenames.<ref>[http://cmv.fossrec.com CharsetMove - Simple Tool for Transcoding Filenames]</ref>\n* convmv \u2013 convert a filename from one encoding to another.<ref>[http://www.j3e.de/linux/convmv/man/ Convmv \u2013 converts filenames from one encoding to another]</ref>\n* cstocs \u2013 convert file contents from one encoding to another for the Czech and Slovak languages.\n* enca \u2013 analyzes encodings for given text files.<ref>[http://directory.fsf.org/project/enca/ Extremely Naive Charset Analyser]</ref>\n* recode \u2013 convert file contents from one encoding to another<ref>[https://www.gnu.org/software/recode/recode.html Recode \u2013 GNU project \u2013 Free Software Foundation (FSF)]</ref>\n* utrac \u2013 convert file contents from one encoding to another.<ref>[http://utrac.sourceforge.net/ Utrac Homepage]</ref>\n\n[[Microsoft Windows|Windows]]:\n* Encoding.Convert \u2013 .NET API<ref>[http://msdn.microsoft.com/en-us/library/system.text.encoding.convert(VS.71).aspx Microsoft .NET Framework Class Library \u2013 Encoding.Convert Method]</ref>\n* MultiByteToWideChar/WideCharToMultiByte \u2013 Convert from ANSI to Unicode & Unicode to ANSI<ref>[http://support.microsoft.com/kb/138813 MultiByteToWideChar/WideCharToMultiByte \u2013 Convert from ANSI to Unicode & Unicode to ANSI]</ref>\n* cscvt \u2013 character set conversion tool<ref>[http://www.cscvt.de/ Kalytta's Character Set Converter]</ref>\n* enca \u2013 analyzes encodings for given text files.<ref>[http://www.john.geek.nz/2010/02/enca-binary-compiled-for-32-bit-windows/ Extremely Naive Charset Analyser]</ref>\n\n== See also ==\n* [[Alt code]]\n* [[Character encodings in HTML]]\n* [[:Category:Character encoding|Character encoding]] \u2013 articles related to character encoding in general\n* [[:Category:Character sets|Character sets]] \u2013 articles detailing specific character encodings\n* [[Hexadecimal#Representing hexadecimal|Hexadecimal representations]]\n* ''[[Mojibake]]'' \u2013 character set mismap.\n* [[Mojikyo]] \u2013 a system (\"glyph set\") that includes over 100,000 Chinese character drawings, modern and ancient, popular and obscure.\n* [[TRON (encoding)|TRON]], part of the TRON project, is an encoding system that does not use Han Unification; instead, it uses \"control codes\" to switch between 16-bit \"planes\" of characters.\n* [[Universal Character Set characters]]\n* [[Charset sniffing]] \u2013 used in some applications when character encoding metadata is not available\n\n=== Common character encodings ===\n{{Div col||30em}}\n* [[ISO/IEC 646|ISO 646]]\n** [[ASCII]]\n* [[Extended Binary Coded Decimal Interchange Code|EBCDIC]]\n** [[EBCDIC 37|CP37]]\n** [[EBCDIC 930|CP930]]\n** [[EBCDIC 1047|CP1047]]\n* [[ISO/IEC 8859|ISO 8859]]:\n** [[ISO/IEC 8859-1|ISO 8859-1]] Western Europe\n** [[ISO/IEC 8859-2|ISO 8859-2]] Western and Central Europe\n** [[ISO/IEC 8859-3|ISO 8859-3]] Western Europe and South European (Turkish, Maltese plus Esperanto)\n** [[ISO/IEC 8859-4|ISO 8859-4]] Western Europe and Baltic countries (Lithuania, Estonia, Latvia and Lapp)\n** [[ISO/IEC 8859-5|ISO 8859-5]] Cyrillic alphabet\n** [[ISO/IEC 8859-6|ISO 8859-6]] Arabic\n** [[ISO/IEC 8859-7|ISO 8859-7]] Greek\n** [[ISO/IEC 8859-8|ISO 8859-8]] Hebrew\n** [[ISO/IEC 8859-9|ISO 8859-9]] Western Europe with amended Turkish character set\n** [[ISO/IEC 8859-10|ISO 8859-10]] Western Europe with rationalised character set for Nordic languages, including complete Icelandic set\n** [[ISO/IEC 8859-11|ISO 8859-11]] Thai\n** [[ISO/IEC 8859-13|ISO 8859-13]] Baltic languages plus Polish\n** [[ISO/IEC 8859-14|ISO 8859-14]] Celtic languages (Irish Gaelic, Scottish, Welsh)\n** [[ISO/IEC 8859-15|ISO 8859-15]] Added the Euro sign and other rationalisations to ISO 8859-1\n** [[ISO/IEC 8859-16|ISO 8859-16]] Central, Eastern and Southern European languages (Albanian, Bosnian, Croatian, Hungarian, Polish, Romanian, Serbian and Slovenian, but also French, German, Italian and Irish Gaelic)\n* [[Code page 437|CP437]], [[Code page 720|CP720]], [[Code page 737|CP737]], [[Code page 850|CP850]], [[Code page 852|CP852]], [[Code page 855|CP855]], [[Code page 857|CP857]], [[Code page 858|CP858]], [[Code page 860|CP860]], [[Code page 861|CP861]], [[Code page 862|CP862]], [[Code page 863|CP863]], [[Code page 865|CP865]], [[Code page 866|CP866]], [[Code page 869|CP869]], [[Code page 872|CP872]]\n* [[Code page#Windows (ANSI) code pages|MS-Windows character sets]]:\n** [[Windows-1250]] for Central European languages that use Latin script, (Polish, Czech, Slovak, Hungarian, Slovene, Serbian, Croatian, Bosnian, Romanian and Albanian)\n** [[Windows-1251]] for Cyrillic alphabets\n** [[Windows-1252]] for Western languages\n** [[Windows-1253]] for Greek\n** [[Windows-1254]] for Turkish\n** [[Windows-1255]] for Hebrew\n** [[Windows-1256]] for Arabic\n** [[Windows-1257]] for Baltic languages\n** [[Windows-1258]] for Vietnamese\n* [[Mac OS Roman]]\n* [[KOI8-R]], [[KOI8-U]], [[KOI7]]\n* [[MIK Code page|MIK]]\n* [[Indian Script Code for Information Interchange|ISCII]]\n* [[Tamil Script Code for Information Interchange|TSCII]]\n* [[Vietnamese Standard Code for Information Interchange|VISCII]]\n* [[JIS X 0208]] is a widely deployed standard for Japanese character encoding that has several encoding forms.\n** [[Shift JIS]] (Microsoft [[Code page 932]] is a dialect of Shift_JIS)\n** [[Extended Unix Code|EUC-JP]]\n** [[ISO/IEC 2022|ISO-2022-JP]]\n* [[JIS X 0213]] is an extended version of JIS X 0208.\n** [[Shift JIS|Shift_JIS-2004]]\n** [[Extended Unix Code|EUC-JIS-2004]]\n** [[ISO/IEC 2022|ISO-2022-JP-2004]]\n* Chinese [[List of GB standards|Guobiao]]\n** [[GB 2312]]\n** [[GBK]] (Microsoft Code page 936)\n** [[GB 18030]]\n* Taiwan [[Big5]] (a more famous variant is Microsoft [[Code page 950]])\n** Hong Kong [[HKSCS]]\n* Korean\n** [[KS X 1001]] is a Korean double-byte character encoding standard\n** [[Extended Unix Code#EUC-KR|EUC-KR]]\n** [[ISO/IEC 2022|ISO-2022-KR]]\n* [[Unicode]] (and subsets thereof, such as the 16-bit 'Basic Multilingual Plane'). See [[UTF-8]]\n* [[ANSEL]] or [[ISO/IEC 6937]]\n{{Div col end}}\n\n== References ==\n{{Reflist|30em}}\n\n== Further reading ==\n* * {{cite book |title=Coded Character Sets, History and Development |work=The Systems Programming Series |last=Mackenzie |first=Charles E. |year=1980 |edition=1 |publisher=[[Addison-Wesley Publishing Company, Inc.]] |isbn=0-201-14460-3 |lccn=77-90165}}\n\n==External links==\n* [http://net-informations.com/q/faq/encoding.html Character Encoding ASCII, ANSI and Unicode]\n* [http://www.iana.org/assignments/character-sets Character sets registered by Internet Assigned Numbers Authority (IANA)]\n* [http://www.cs.tut.fi/~jkorpela/chars/index.html Characters and encodings], by Jukka Korpela\n* [http://www.unicode.org/unicode/reports/tr17/ Unicode Technical Report #17: Character Encoding Model]\n* [http://code.cside.com/3rdpage/us/unicode/converter.html Decimal, Hexadecimal Character Codes in HTML Unicode - Encoding converter]\n\n{{Character encoding|state=collapsed}}\n\n{{DEFAULTSORT:Character Encoding}}\n[[Category:Character encoding| ]]\n[[Category:Natural language and computing|Encoding]]"}]}}}}