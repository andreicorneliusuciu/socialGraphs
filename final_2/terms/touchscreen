{"batchcomplete":"","query":{"pages":{"667206":{"pageid":667206,"ns":0,"title":"Touchscreen","revisions":[{"contentformat":"text/x-wiki","contentmodel":"wikitext","*":"{{redirect|Touch sensitive|other uses|Touch Sensitive (disambiguation){{!}}Touch Sensitive}}\nA '''touchscreen''' is  an important source of [[input device]] and [[output device]]  normally layered on the top of an [[electronic visual display]] of an [[information processing system]]. A user can give input or control the [[information processing system]] through simple or [[Multi-touch|multi-touch gestures]] by touching the screen with a special [[Stylus (computing)|stylus]] and/or one or more fingers.<ref>{{cite journal|last1=Walker|first1=Geoff|title=A review of technologies for sensing contact location on the surface of a display|journal=Journal of the Society for Information Display|date=August 2012|volume=20|issue=8|pages=413\u2013440|doi=10.1002/jsid.100|url=http://onlinelibrary.wiley.com/doi/10.1002/jsid.100/abstract}}</ref> Some touchscreens use ordinary or specially coated gloves to work while others use a special stylus/pen only. The user can use the touchscreen to react to what is displayed and to control  how it is displayed; for example, [[Multi-touch gestures|zooming]] to increase the text size.\n\nThe touchscreen enables the user to interact directly with what is displayed, rather than using a [[mouse (computing)|mouse]], [[touchpad]], or any other intermediate device (other than a stylus, which is optional for most modern touchscreens).\n\nTouchscreens are common in devices such as [[game consoles]], [[personal computer]]s, [[tablet computer]]s, [[electronic voting machine]]s, and [[smartphone]]s. They can also be attached to computers or, as terminals, to networks. They also play a prominent role in the design of digital appliances such as [[personal digital assistant|personal digital assistants (PDAs)]] and some [[e-reader]]s.\n\nThe popularity of smartphones, tablets, and many types of [[information appliance]]s is driving the demand and acceptance of common touchscreens for portable and functional electronics. Touchscreens are found in the medical field and in [[heavy industry]], as well as for [[automated teller machine]]s (ATMs), and kiosks such as museum displays or [[room automation]], where [[keyboard (computing)|keyboard]] and [[mouse (computing)|mouse]] systems do not allow a suitably intuitive, rapid, or accurate interaction by the user with the display's content.\n\nHistorically, the touchscreen sensor and its accompanying controller-based [[firmware]] have been made available by a wide array of after-market [[system integrator]]s, and not by display, chip, or [[motherboard]] manufacturers. Display manufacturers and chip manufacturers worldwide have acknowledged the trend toward acceptance of touchscreens as a highly desirable [[user interface]] component and have begun to integrate touchscreens into the fundamental design of their products.\n\n==History==\n[[File:CERN-Stumpe Capacitance Touchscreen.jpg|thumb|The prototype<ref>{{Cite journal\n |publisher=CERN Courrier\n |date=31 March 2010\n |title=The first capacitative touch screens at CERN\n |url=http://cerncourier.com/cws/article/cern/42092\n |accessdate=2010-05-25\n |postscript=<!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. -->{{inconsistent citations}}\n}}</ref> x-y mutual capacitance touchscreen (left) developed at [[CERN]]<ref>{{Cite journal\n |publisher=CERN\n |author=Bent STUMPE\n |date=16 March 1977\n |title=A new principle for x-y touch system\n |url=http://cdsweb.cern.ch/record/1266588/files/StumpeMar77.pdf\n |accessdate=2010-05-25\n |postscript=<!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. -->{{inconsistent citations}}\n}}</ref><ref>{{Cite journal\n |publisher=CERN\n |author=Bent STUMPE\n |date=6 February 1978\n |title=Experiments to find a manufacturing process for an x-y touch screen\n |url=http://cdsweb.cern.ch/record/1266589/files/StumpeFeb78.pdf\n |accessdate=2010-05-25\n |postscript=<!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. -->{{inconsistent citations}}\n}}</ref> in 1977 by Bent Stumpe, a Danish electronics engineer, for the control room of CERN\u2019s accelerator SPS ([[Super Proton Synchrotron]]). This was a further development of the [[Capacitive sensing|self-capacitance screen]] (right), also developed by Stumpe at CERN<ref>{{Cite journal\n |publisher=CERN\n |author=Frank BECK & Bent STUMPE\n |date=24 May 1973\n |title=Two devices for operator interaction in the central control of the new CERN accelerator\n |url=http://cdsweb.cern.ch/record/186242/files/p1.pdf\n |accessdate=2010-05-25\n |postscript=<!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. -->{{inconsistent citations}}\n}}</ref> in 1972.]]\nE.A. Johnson of the Royal Radar Establishment, Malvern described his work on capacitive touchscreens in a short article published in 1965<ref>{{cite journal|last=Johnson|first=E.A.|title=Touch Display - A novel input/output device for computers|journal=Electronics Letters|year=1965|volume=1|issue=8|pages=219\u2013220|doi=10.1049/el:19650200}}</ref> and then more fully\u2014with photographs and diagrams\u2014in an article published in 1967.<ref>{{cite journal|last=Johnson|first=E.A.|title= Touch Displays: A Programmed Man-Machine Interface|journal=Ergonomics|year=1967|volume=10|issue=2|pages=271\u2013277|doi=10.1080/00140136708930868}}</ref> The applicability of touch technology for air traffic control was described in an article published in 1968.<ref>{{cite journal|last=Orr|first=N.W.|author2=Hopkins, V.D. |title=The Role of Touch Display in Air Traffic Control|journal=The Controller|year=1968|volume=7|pages=7\u20139}}</ref> [[Frank_Beck_(computer_scientist)|Frank Beck]] and Bent Stumpe, engineers from [[CERN]], developed a transparent touchscreen in the early 1970s, based on Stumpe's work at a television factory in the early 1960s. Then manufactured by CERN, it was put to use in 1973.<ref>{{cite web|url=http://cdsweb.cern.ch/record/1248908|title=Another of CERN's many inventions! - CERN Document Server|work=CERN Document Server|accessdate=29 July 2015}}</ref>  A resistive touchscreen was developed by American inventor [[George Samuel Hurst]], who received US patent #3,911,215 on October 7, 1975.<ref name=HurstPat>{{cite web|last=USPTO|title=DISCRIMINATING CONTACT SENSOR|url=http://www.google.com/patents/US3911215|publisher=Google|accessdate=6 April 2013}}</ref>  The first version was produced in 1982.<ref>[http://www.oakridger.com/columnists/x860698067/G-Samuel-Hurst-the-Tom-Edison-of-ORNL?zc_p=1 oakridger.com, \"G. Samuel Hurst -- the 'Tom Edison' of ORNL\", December 14 2010].</ref>\n\nIn 1972, a group at the [[University of Illinois]] filed for a patent on an optical touchscreen<ref>F. Ebeling, R. Johnson, R. Goldhor, Infrared light beam x-y position encoder for display devices, {{patent|US|3775560}}, granted November 27, 1973.</ref>  that became a standard part of the [[Magnavox]] Plato IV Student Terminal. Thousands were built for the [[PLATO IV]] system.  These touchscreens had a crossed array of 16 by 16 [[infrared]] position sensors, each composed of an [[LED]] on one edge of the screen and a matched [[phototransistor]] on the other edge, all mounted in front of a monochrome plasma display panel.  This arrangement can sense any fingertip-sized opaque object in close proximity to the screen.  A similar touchscreen was used on  the [[HP-150]] starting in 1983; this was one of the world's earliest commercial touchscreen computers.<ref>[http://www.youtube.com/watch?feature=player_detailpage&v=X-THdG5gVTw#t=46s The H.P. Touch Computer (1983)]. YouTube (2008-02-19). Retrieved on 2013-08-16.</ref>  HP mounted their [[infrared]] [[transmitter]]s and receivers around the bezel of a 9\" [[Sony]] [[Cathode Ray Tube]] (CRT).\n\nIn 1984, [[Fujitsu]] released a touch pad for the [[Fujitsu Micro 16s|Micro 16]], to deal with the complexity of [[kanji]] characters, which were stored as [[Tile engine|tiled]] graphics.<ref>[https://www.youtube.com/watch?v=rbh1XP4kCT4 Japanese PCs (1984)] (12:21), ''[[Computer Chronicles]]''</ref> In 1985, [[Sega]] released the Terebi Oekaki, also known as the Sega Graphic Board, for the [[SG-1000]] [[video game console]] and [[SC-3000]] [[home computer]]. It consisted of a plastic pen and a plastic board with a transparent window where the pen presses are detected. It was used primarily for a drawing software application.<ref>{{cite web|url=http://www.smspower.org/Articles/TerebiOekaki|title=Terebi Oekaki / Sega Graphic Board - Articles - SMS Power!|publisher=|accessdate=29 July 2015}}</ref> A graphic touch tablet was released for the Sega AI Computer in 1986.<ref>[https://books.google.co.uk/books?id=RI51dkpbcGoC&pg=PA34 ''New Scientist'' (March 26, 1987), page 34]</ref><ref>[http://archive.computerhistory.org/resources/access/text/2013/04/102723432-05-01-acc.pdf#page=87 Technology Trends: 2nd Quarter 1986], ''Japanese Semiconductor Industry Service - Volume II: Technology & Government''</ref>\n\nTouch-sensitive Control-Display Units (CDUs)were evaluated for commercial aircraft flight decks in the early 1980s. Initial research showed that a touch interface would reduce pilot workload as the crew could then select waypoints, functions and actions, rather than be \"head down\" typing in latitudes, longitudes, and waypoint codes on a keyboard.  An effective integration of this technology was aimed at helping flight crews maintain a high-level of situational awareness of all major aspects of the vehicle operations including its flight path, the functioning of various aircraft systems, and moment-to-moment human interactions. <ref> Biferno, M.A., Stanley, D.L. (1983). The Touch-Sensitive Control/Display Unit: A promising Computer Interface. Technical Paper 831532, Aerospace Congress & Exposition, Long Beach, CA: Society of Automotive Engineers.</ref>\n\nIn the early 1980s, [[General Motors]] tasked its [[Delco Electronics]] division with a project aimed at replacing an automobile's non essential functions (i.e. other than throttle, transmission, braking and steering) from mechanical or electro-mechanical systems with [[solid state (electronics)|solid state]] alternatives wherever possible. The finished device was dubbed the ECC for \"Electronic Control Center\", a [[digital computer]] and [[software]] control system hardwired to various [[peripheral]] [[sensors]], [[servos]], [[solenoids]], [[Antenna (radio)|antenna]] and a [[monochrome]] CRT touchscreen that functioned both as display and sole method of input.<ref>{{cite web|url=http://history.gmheritagecenter.com/wiki/index.php/1986,_Electronics_Developed_for_Lotus_Active_Suspension_Technology |title=1986, Electronics Developed for Lotus Active Suspension Technology - Generations of GM |publisher=History.gmheritagecenter.com |accessdate=2013-01-07}}</ref> The ECC replaced the traditional mechanical [[Vehicle audio|stereo]], fan, heater and [[automobile air conditioning|air conditioner]] controls and displays, and was capable of providing very detailed and specific information about the vehicle's cumulative and current operating status in [[real-time computer graphics|real time]]. The ECC was standard equipment on the 1985\u201389 [[Buick Riviera#Seventh generation|Buick Riviera]] and later the 1988\u201389 [[Buick Reatta]], but was unpopular with consumers partly due to the [[technophobia]] of some traditional [[Buick]] customers, but mostly because of costly to repair technical problems suffered by the ECC's touchscreen which being the sole access method, would render climate control or stereo operation impossible.<ref>{{cite web|last=Badal |first=Jaclyne |url=http://online.wsj.com/article/SB121390461372989357.html |title=When Design Goes Bad - WSJ.com |publisher=Online.wsj.com |date=2008-06-23 |accessdate=2013-01-07}}</ref>\n\n[[Multi-touch technology]] began in 1982, when the University of Toronto's Input Research Group developed the first human-input multi-touch system, using a frosted-glass panel with a camera placed behind the glass.  In 1985, the University of Toronto group including Bill Buxton developed a multi-touch tablet that used capacitance rather than bulky camera-based optical sensing systems (see [[Multi-touch#History of multi-touch|History of multi-touch]]).\n\nIn 1986, the first graphical point of sale software was demonstrated on the 16-bit [[Atari 520ST]] color computer. It featured a color touchscreen widget-driven interface.<ref>[http://www.atarimagazines.com/startv2n6/gettingdowntobusiness.html The ViewTouch restaurant system] by Giselle Bisson</ref>  The ViewTouch<ref>{{cite web|url=http://www.viewtouch.com |title=The World Leader in GNU-Linux Restaurant POS Software |publisher=Viewtouch.com |accessdate=2013-01-07}}</ref> point of sale software was first shown by its developer, Gene Mosher, at Fall Comdex, 1986, in Las Vegas, Nevada to visitors at the Atari Computer demonstration area and was the first commercially available POS system with a widget-driven color graphic touchscreen interface.<ref>{{cite web|url=http://commons.wikimedia.org/wiki/File:Comdex_1986.png |title=File:Comdex 1986.png - Wikimedia Commons |publisher=Commons.wikimedia.org |accessdate=2013-01-07}}</ref>\n\nIn 1987, Casio launched the [[Casio PB-1000]] pocket computer with a touchscreen consisting of a 4x4 matrix, resulting in 16 touch areas in its small LCD graphic screen.\n\nUntil 1988 touchscreens had the bad reputation of being imprecise. Most user interface books would state that touchscreens selections were limited to targets larger than the average finger.  At the time, selections were done in such a way that a target was selected as soon as the finger came over it, and the corresponding action was performed immediately. Errors were common, due to parallax or calibration problems, leading to frustration.  A new strategy called \"lift-off strategy\"<ref name=Potter1988>{{cite conference|authors=Potter, R., Weldon, L., Shneiderman, B.|title=Improving the accuracy of touch screens: an experimental evaluation of three strategies|conference=Proc. of the Conference on Human Factors in Computing Systems, CHI '88|location=Washington, DC|pages=27\u201332|doi=10.1145/57167.57171|url=http://www.cs.umd.edu/localphp/hcil/tech-reports-search.php?number=88-04}}</ref> was introduced by researchers at the [[University of Maryland Human \u2013 Computer Interaction Lab]] and is still used today. As users touch the screen, feedback is provided as to what will be selected, users can adjust the position of the finger, and the action takes place only when the finger is lifted off the screen. This allowed the selection of small targets, down to a single pixel on a VGA screen (standard best of the time).\n\nSears et al. (1990)<ref name=Sears1990>{{cite book|authors=Andrew Sears, [[Catherine Plaisant]], [[Ben Shneiderman]]|date=June 1990|contribution=A new era for high-precision touchscreens|title=Advances in Human-Computer Interaction|volume=3|editors=Hartson, R. & Hix, D. |publisher=Ablex (1992)|number= 1-33 HCIL-90-01, CS-TR-2487, CAR-TR-506.|url=http://www.cs.umd.edu/local-cgi-bin/hcil/rr.pl?number=90-01|isbn=0-89391-751-6|archiveurl=https://web.archive.org/web/20141009003729/http://www.cs.umd.edu/local-cgi-bin/hcil/rr.pl?number=90-01|archivedate=October 9, 2014}}</ref> gave a review of academic research on single and [[multi-touch]] [[human\u2013computer interaction]] of the time, describing gestures such as rotating knobs, adjusting sliders, and swiping the screen to activate a switch (or a U-shaped gesture for a toggle switch).  The [[University of Maryland Human \u2013 Computer Interaction Lab]] team developed and studied small touchscreen keyboards (including a study that showed that users could type at 25 wpm for a touchscreen keyboard compared with 58 wpm for a standard keyboard), thereby paving the way for the touchscreen keyboards on mobile devices.  They also designed and implemented multitouch gestures such as selecting a range of a line, connecting objects, and a \"tap-click\" gesture to select while maintaining location with another finger.\n\nIn 1990 the [[University of Maryland Human \u2013 Computer Interaction Lab]] demonstrated a touchscreen slider,<ref name=\"Touchscreen slider 1991 video\">{{cite web|title=1991 video of the HCIL touchscreen toggle switches (University of Maryland)|url=https://www.youtube.com/watch?v=wFWbdxicvK0|accessdate=3 December 2015}}</ref> which was later cited as prior art in the [[lock screen]] patent litigation between Apple and other touchscreen mobile phone vendors (in relation to {{US patent|7657849}}).<ref name=UKChannel4News2011>{{cite AV media|title=Apple touch-screen patent war comes to the UK (2011)|url=http://www.channel4.com/news/apple-touch-screen-patent-war-comes-to-the-uk|accessdate= 3 December 2015|time=1:24 min in video}}</ref>\n\nIn c. 1991\u201392, the [[Sun Microsystems|Sun]] Star7 prototype [[Personal digital assistant|PDA]] implemented a touchscreen with [[Scrolling#computing|inertial scrolling]].<ref>{{YouTube|id=1CsTH9S79qI&t=4m28s|title=Star7 Demo}}. Retrieved on 2013-08-16.</ref>  In 1993, the [[IBM Simon]]\u2014the first touchscreen phone\u2014was released.\n\nAn early attempt at a [[handheld game console]] with touchscreen [[game controller|controls]] was [[Sega]]'s intended successor to the [[Game Gear]], though the device was ultimately shelved and never released due to the expensive cost of touchscreen technology in the early 1990s. Touchscreens would not be popularly used for video games until the release of the [[Nintendo DS]] in 2004.<ref>{{cite web|url=http://retro.ign.com/articles/974/974695p7.html|title=IGN Presents the History of SEGA|page=7|publisher=IGN|author=Travis Fahs|date=April 21, 2009|accessdate=2011-04-27}}</ref> Until recently, most consumer touchscreens could only sense one point of contact at a time, and few have had the capability to sense how hard one is touching. This has changed with the commercialization of [[multi-touch]] technology.\n\n==Technologies==\nThere are a variety of touchscreen technologies with different methods of sensing touch.<ref name=Sears1990/>\n\n===Resistive===\n{{Main|Resistive touchscreen}}\nA [[resistive]] touchscreen panel comprises several layers, the most important of which are two thin, transparent electrically-resistive layers separated by a thin space. These layers face each other with a thin gap between. The top screen (the screen that is touched) has a coating on the underside surface of the screen. Just beneath it is a similar resistive layer on top of its substrate. One layer has conductive connections along its sides, the other along top and bottom. A voltage is applied to one layer, and sensed by the other. When an object, such as a fingertip or stylus tip, presses down onto the outer surface, the two layers touch to become connected at that point: The panel then behaves as a pair of [[voltage divider]]s, one axis at a time. By rapidly switching between each layer, the position of a pressure on the screen can be read.\n\nResistive touch is used in restaurants, factories and hospitals due to its high resistance to liquids and contaminants. A major benefit of resistive touch technology is its low cost. Additionally, as only sufficient pressure is necessary for the touch to be sensed, they may be used with gloves on, or by using anything rigid as a finger/stylus substitute. Disadvantages include the need to press down, and a risk of damage by sharp objects. Resistive touchscreens also suffer from poorer contrast, due to having additional reflections from the extra layers of material (separated by an air gap) placed over the screen.<ref>Lancet, Yaara. (2012-07-19) [http://www.makeuseof.com/tag/differences-capacitive-resistive-touchscreens-si/ What Are The Differences Between Capacitive & Resistive Touchscreens?]. Makeuseof.com. Retrieved on 2013-08-16.</ref> This is the type of touchscreen used by Nintendo in the [[Nintendo DS line|DS family]], the [[Nintendo 3DS line|3DS family]], and the [[Wii U GamePad]].<ref>{{cite web|url=http://www.engadget.com/2011/06/13/nintendo-3ds-has-resistive-touchscreen-for-backwards-compatibili/|title=Nintendo 3DS has resistive touchscreen for backwards compatibility, what's the Wii U's excuse?|author=Vlad Savov|publisher=AOL|work=Engadget|accessdate=29 July 2015}}</ref>\n\n===Surface acoustic wave===\n{{Main|Surface acoustic wave}}\n\nSurface acoustic wave (SAW) technology uses [[ultrasound|ultrasonic]] waves that pass over the touchscreen panel. When the panel is touched, a portion of the wave is absorbed. This change in the ultrasonic waves registers the position of the touch event and sends this information to the [[controller (computing)|controller]] for processing. Surface acoustic wave touchscreen panels can be damaged by outside elements. Contaminants on the surface can also interfere with the functionality of the touchscreen.{{Citation needed|date=October 2013}}\n\n===Capacitive===\n[[File:Capacitive touchscreen.jpg|thumb|Capacitive touchscreen of a mobile phone]]\n{{Main|Capacitive sensing}}\n\nA capacitive touchscreen panel consists of an [[insulator (electrical)|insulator]] such as [[glass]], coated with a transparent [[electrical conductor|conductor]] such as [[indium tin oxide]] (ITO).<ref>{{cite web|title=Index-matched indium tin oxide electrodes for capacitive touch screen panel applications.|url=http://www.ncbi.nlm.nih.gov/pubmed/24245328|publisher=U.S. National Library of Medicine|accessdate=23 May 2015}}</ref> As the human body is also an electrical conductor, touching the surface of the screen results in a distortion of the screen's [[electrostatic]] field, measurable as a change in [[capacitance]]. Different technologies may be used to determine the location of the touch. The location is then sent to the [[Controller (computing)|controller]] for processing.\n\nUnlike a [[resistive touchscreen]], one cannot use a capacitive touchscreen through most types of electrically insulating material, such as gloves. This disadvantage especially affects usability in consumer electronics, such as touch tablet PCs and capacitive smartphones in cold weather. It can be overcome with a special capacitive stylus, or a special-application glove with an embroidered patch of conductive thread passing through it and contacting the user's fingertip.\n\nThe largest capacitive display manufacturers continue to develop thinner and more accurate touchscreens, with touchscreens for [[mobile device]]s now being produced with 'in-cell' technology that eliminates a layer, such as Samsung's [[AMOLED#Super AMOLED|Super AMOLED]] screens, by building the capacitors inside the display itself. This type of touchscreen reduces the visible distance (within millimetres) between the user's finger and what the user is touching on the screen, creating a more direct contact with the content displayed and enabling [[Multi-touch|taps and gestures]] to be more responsive.\n\nA simple parallel plate capacitor has two conductors separated by a dielectric layer. Most of the energy in this system is concentrated directly between the plates. Some of the energy spills over into the area outside the plates, and the electric field lines associated with this effect are called fringing fields. Part of the challenge of making a practical capacitive sensor is to design a set of printed circuit traces which direct fringing fields into an active sensing area accessible to a user. A parallel plate capacitor is not a good choice for such a sensor pattern. Placing a finger near fringing electric fields adds conductive surface area to the capacitive system. The additional charge storage capacity added by the finger is known as finger capacitance, CF. The capacitance of the sensor without a finger present is denoted as CP in this article, which stands for parasitic capacitance.\n\n====Surface capacitance====\nIn this basic technology, only one side of the insulator is coated with a conductive layer. A small [[voltage]] is applied to the layer, resulting in a uniform electrostatic field. When a [[electrical conductor|conductor]], such as a human finger, touches the uncoated surface, a [[capacitor]] is dynamically formed. The sensor's [[controller (computing)|controller]] can determine the location of the touch indirectly from the change in the [[capacitance]] as measured from the four corners of the panel. As it has no moving parts, it is moderately durable but has limited resolution, is prone to false signals from parasitic [[capacitive coupling]], and needs [[calibration]] during manufacture. It is therefore most often used in simple applications such as industrial controls and [[interactive kiosk|kiosks]].<ref>{{cite web|url=http://electronicdesign.com/Articles/Index.cfm?AD=1&ArticleID=18592 |title=Please Touch! Explore The Evolving World Of Touchscreen Technology |publisher=electronicdesign.com |accessdate=2009-09-02}}</ref>\n\n====Projected capacitance====\n[[File:PCT Globe.jpg|thumb|Back side of a Multitouch Globe, based on Projected Capacitive Touch (PCT) technology]]\n[[File:TouchScreen projective capacitive.svg|thumb|Schema of projected-capacitive touchscreen]]\nProjected capacitive touch (PCT; also PCAP) technology is a variant of capacitive touch technology. All PCT touch screens are made up of a matrix of rows and columns of conductive material, layered on sheets of glass. This can be done either by [[etching (microfabrication)|etching]] a single conductive layer to form a grid pattern of [[electrode]]s, or by etching two separate, perpendicular layers of conductive material with parallel lines or tracks to form a grid. Voltage applied to this grid creates a uniform electrostatic field, which can be measured. When a conductive object, such as a finger, comes into contact with a PCT panel, it distorts the local electrostatic field at that point. This is measurable as a change in capacitance. If a finger bridges the gap between two of the \"tracks\", the charge field is further interrupted and detected by the controller. The capacitance can be changed and measured at every individual point on the grid (intersection). Therefore, this system is able to accurately track touches.<ref>Knowledge base: [http://www.multi-touch-solution.com/en/knowledge-base-en/multitouch-technologies-en/ Multi-touch hardware]</ref>\nDue to the top layer of a PCT being glass, it is a more robust solution than less costly resistive touch technology. Additionally, unlike traditional capacitive touch technology, it is possible for a PCT system to sense a passive stylus or gloved fingers. However, moisture on the surface of the panel, high humidity, or collected dust can interfere with the performance of a PCT system. There are two types of PCT: mutual capacitance and self-capacitance.\n\n=====Mutual capacitance=====\nThis is a common PCT approach, which makes use of the fact that most conductive objects are able to hold a charge if they are very close together. In mutual capacitive sensors, a [[capacitor]] is inherently formed by the row trace and column trace at each intersection of the grid. A 16-by-14 array, for example, would have 224 independent capacitors. A [[voltage]] is applied to the rows or columns. Bringing a finger or conductive stylus close to the surface of the sensor changes the local electrostatic field which reduces the mutual capacitance. The capacitance change at every individual point on the grid can be measured to accurately determine the touch location by measuring the voltage in the other axis. Mutual capacitance allows [[multi-touch]] operation where multiple fingers, palms or styli can be accurately tracked at the same time.\n\n=====Self-capacitance=====\nSelf-capacitance sensors can have the same X-Y grid as mutual capacitance sensors, but the columns and rows operate independently. With self-capacitance, the capacitive load of a finger is measured on each column or row electrode by a current meter. This method produces a stronger signal than mutual capacitance, but it is unable to resolve accurately more than one finger, which results in \"ghosting\", or misplaced location sensing.\n\n====Use of styli on capacitive screens====\nCapacitive touchscreens don't necessarily need to be operated by a finger, but until recently the special styli required could be quite expensive to purchase. The cost of this technology has fallen greatly in recent years and capacitative styli are now widely available for a nominal charge, and often given away free with mobile accessories.\n\n===Infrared grid===\n[[Image:Platovterm1981.jpg|right|thumb|Infrared sensors mounted around the display watch for a user's touchscreen input on this PLATO V terminal in 1981. The monochromatic plasma display's characteristic orange glow is illustrated.]]\n\nAn [[infrared]] touchscreen uses an array of X-Y infrared [[light-emitting diode|LED]] and [[photodetector]] pairs around the edges of the screen to detect a disruption in the pattern of LED beams. These LED beams cross each other in vertical and horizontal patterns. This helps the sensors pick up the exact location of the touch. A major benefit of such a system is that it can detect essentially any input including a finger, gloved finger, stylus or pen. It is generally used in outdoor applications and [[point of sale]] systems which can not rely on a [[electrical conductor|conductor]] (such as a bare finger) to activate the touchscreen. Unlike [[capacitive sensing|capacitive touchscreens]], infrared touchscreens do not require any patterning on the glass which increases durability and optical clarity of the overall system. Infrared touchscreens are sensitive to dirt/dust that can interfere with the IR beams, and suffer from parallax in curved surfaces and accidental press when the user hovers his/her finger over the screen while searching for the item to be selected.\n\n===Infrared acrylic projection===\nA translucent acrylic sheet is used as a rear projection screen to display information.  The edges of the acrylic sheet are illuminated by infrared LEDs, and infrared cameras are focused on the back of the sheet.  Objects placed on the sheet are detectable by the cameras.  When the sheet is touched by the user the deformation results in leakage of infrared light, which peaks at the points of maximum pressure indicating the user's touch location.  Microsoft's [[Microsoft PixelSense|PixelSense]] tables use this technology.\n\n===Optical imaging===\nOptical touchscreens are a relatively modern development in touchscreen technology, in which two or more image sensors are placed around the edges (mostly the corners) of the screen. Infrared back lights are placed in the camera's field of view on the other side of the screen. A touch shows up as a shadow and each pair of cameras can then be pinpointed to locate the touch or even measure the size of the touching object (see [[Visual hull#In two dimensions|visual hull]]). This technology is growing in popularity, due to its scalability, versatility, and affordability, especially for bigger units.\n\n===Dispersive signal technology===\nIntroduced in 2002, by [[3M]], this system uses sensors to detect the [[piezoelectricity]] in the glass that occurs due to a touch. Complex algorithms then interpret this information and provide the actual location of the touch.<ref>{{cite web |accessdate=2009-03-16 |url=http://www.fool.com/investing/general/2008/02/13/innovation-series-touchscreen-technology.aspx |title=Innovation Series: Touchscreen Technology |work=The Motley Fool |date=2008-02-13 |author=Beyers, Tim}}</ref> The technology claims to be unaffected by dust and other outside elements, including scratches. Since there is no need for additional elements on screen, it also claims to provide excellent optical clarity. Also, since mechanical vibrations are used to detect a touch event, any object can be used to generate these events, including fingers and stylus. A downside is that after the initial touch the system cannot detect a motionless finger.\n\n===Acoustic pulse recognition===\nThe key to  this technology is that a touch at any one position on the surface generates a sound wave in the substrate which then produces a unique combined sound after being picked up by three or more tiny transducers attached to the edges of the touchscreen. The sound is then digitized by the controller and to a list of pre-recorded sounds for every position on the surface. The cursor position is instantly updated to the touch location. A moving touch is tracked by rapid repetition of this process. Extraneous and ambient sounds are ignored since they do not match any stored sound profile. The technology differs from other attempts to recognize the position of touch with transducers or microphones in using a simple table look-up method, rather than requiring powerful and expensive signal processing hardware to attempt to calculate the touch location without any references. As with the dispersive signal technology system, a motionless finger cannot be detected after the initial touch. However, for the same reason, the touch recognition is not disrupted by any resting objects. The technology was created by SoundTouch Ltd in the early 2000s, as described by the patent family EP1852772, and introduced to the market by [[Tyco International]]'s Elo division in 2006 as Acoustic Pulse Recognition.<ref>{{Cite journal\n | last =\n | first =\n | title =Acoustic Pulse Recognition Touchscreens\n | work =\n | page = 3\n | language =\n | publisher =Elo Touch Systems\n | year = 2006\n | url = http://media.elotouch.com/pdfs/marcom/apr_wp.pdf\n | accessdate = 2011-09-27\n | postscript =<!--None--> }}</ref> The touchscreen used by Elo is made of ordinary glass, giving good durability and optical clarity. APR is usually able to function with scratches and dust on the screen with good accuracy. The technology is also well suited to displays that are physically larger.\n\n==Construction==\nThere are several principal ways to build a touchscreen. The key goals are to recognize one or more fingers touching a display, to interpret the command that this represents, and to communicate the command to the appropriate application.\n\nIn the most popular techniques, the capacitive or resistive approach, there are typically four layers:\n\n# Top polyester coated with a transparent metallic conductive coating on the bottom.\n# Adhesive spacer\n# Glass layer coated with a transparent metallic conductive coating on the top\n# Adhesive layer on the backside of the glass for mounting.\n\nWhen a user touches the surface, the system records the change in the electric current that flows through the display.\n\nDispersive-signal technology which [[3M]] created in 2002, measures the [[piezoelectric effect]]\u2014the voltage generated when mechanical force is applied to a material\u2014that occurs chemically when a strengthened glass substrate is touched.\n\nThere are two infrared-based approaches. In one, an array of sensors detects a finger touching or almost touching the display, thereby interrupting light beams projected over the screen. In the other, bottom-mounted [[thermographic camera|infrared cameras]] record screen touches.\n\nIn each case, the system determines the intended command based on the controls showing on the screen at the time and the location of the touch.\n\n==Development==\nThe development of multipoint touchscreens facilitated the tracking of more than one finger on the screen; thus, operations that require more than one finger are possible. These devices also allow multiple users to interact with the touchscreen simultaneously.\n\nWith the growing use of touchscreens, the [[marginal cost]] of touchscreen technology is routinely absorbed into the products that incorporate it and is nearly eliminated. Touchscreens now have proven reliability. Thus, touchscreen displays are found today in airplanes, automobiles, gaming consoles, machine control systems, appliances, and handheld display devices including the [[Nintendo DS]] and multi-touch enabled cellphones; the touchscreen market for mobile devices was projected to produce US$5 billion by 2009.<ref>{{cite web|url=http://www.abiresearch.com/press/1231-Touch+Screens+in+Mobile+Devices+to+Deliver+$5+Billion+Next+Year |title=Touch Screens in Mobile Devices to Deliver $5 Billion Next Year &#124; Press Release |publisher=ABI Research |date=2008-09-10 |accessdate=2009-06-22}}</ref>\n\nThe ability to accurately point on the screen itself is also advancing with the emerging [[graphics tablet/screen hybrid]]s. [[Polyvinylidene fluoride|PVDF]] plays a major role in this innovation due its high piezoelectric properties.<ref>{{Cite web|url = http://www.fluorotherm.com/insights-into-pvdf-innovations/|title = Insights Into PVDF Innovations|date = 17 August 2015|accessdate = |website = |publisher = Fluorotherm|last = |first = }}</ref>\n\nTapSense, announced in October 2011, allows touchscreens to distinguish what part of the hand was used for input, such as the fingertip, knuckle and fingernail. This could be used in a variety of ways, for example, to copy and paste, to capitalize letters, to activate different drawing modes, and similar.<ref>{{cite web |url=http://techcrunch.com/2011/10/19/new-screen-technology-tapsense-can-distinguish-between-different-parts-of-your-hand/?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+Techcrunch+%28TechCrunch%29 |title=New Screen Technology, TapSense, Can Distinguish Between Different Parts Of Your Hand |accessdate=October 19, 2011}}</ref><ref>{{cite web|title=TapSense: Enhancing Finger Interaction on Touch Surfaces|url=http://www.chrisharrison.net/index.php/Research/TapSense/|accessdate=28 January 2012}}</ref>\n\n==Ergonomics and usage==\n\n===Touchscreen accuracy===\nUsers must be able to accurately select targets on touchscreens, and avoid accidental selection of adjacent targets, to effectively use a touchscreen input device. The design of touchscreen interfaces must reflect both technical capabilities of the system, [[Human factors and ergonomics|ergonomics]], [[cognitive psychology]] and [[human physiology]].\n\nGuidelines for touchscreen designs were first developed in the 1990s, based on early research and actual use of older systems, so assume the use of contemporary sensing technology such as infrared grids. These types of touchscreens are highly dependent on the size of the user's fingers, so their guidelines are less relevant for the bulk of modern devices, using capacitive or resistive touch technology.<ref>{{cite journal|title= ANSI/HFES 100-2007 Human Factors Engineering of Computer Workstations|journal=Human Factors & Ergonomics Society|year=2007|location = Santa Monica, CA}}</ref><ref>{{cite journal|title= Ergonomic Requirements for Office Work with Visual Display Terminals (VDTs)\u2013Part 9: Requirements for Non-keyboard Input Devices|journal=International Organization for Standardization|year=2000|location = Geneva, Switzerland}}</ref> From the mid-2000s onward, makers of [[operating systems]] for [[smartphones]] have promulgated standards, but these vary between manufacturers, and allow for significant variation in size based on technology changes, so are unsuitable from a [[Human factors and ergonomics|human factors]] perspective.<ref>{{cite web|url=https://developer.apple.com/library/ios/documentation/userexperience/conceptual/mobilehig/LayoutandAppearance.html |title=iOS Human Interface Guidelines |publisher=Apple |accessdate=2014-08-24}}</ref><ref>{{cite web|url=http://developer.android.com/design/style/metrics-grids.html |title=Metrics and Grids |publisher=Google |accessdate=2014-08-24}}</ref><ref>{{cite web|url=http://msdn.microsoft.com/en-us/library/windows/apps/hh465415.aspx |title=Touch interactions for Windows |publisher=Microsoft |accessdate=2014-08-24}}</ref>\n\nMuch more important is the accuracy humans have in selecting targets with their finger or a pen stylus. The accuracy of user selection varies by position on the screen. Users are most accurate at the center, less so at the left and right edges, and much less accurate at the top and especially bottom edges. The [[Circular error probable|R95]] accuracy varies from 7&nbsp;mm in the center, to 12&nbsp;mm in the lower corners.<ref>{{cite web|last = Hoober | first = Steven | url = http://www.uxmatters.com/mt/archives/2013/03/common-misconceptions-about-touch.php | title = Common Misconceptions About Touch | publisher = UXmatters | date = 2013-02-18 | accessdate = 2014-08-24}}</ref><ref>{{cite web|last = Hoober | first = Steven | url = http://www.uxmatters.com/mt/archives/2013/11/design-for-fingers-and-thumbs-instead-of-touch.php | title = Design for Fingers and Thumbs Instead of Touch | publisher = UXmatters | date = 2013-11-11 | accessdate = 2014-08-24}}</ref><ref>{{cite journal|last1 = Hoober| first1 = Steven|last2 = Shank| first2 = Patti|last3 = Boll| first3 = Susanne| title= Making mLearning Usable: How We Use Mobile Devices|year=2014|location = Santa Rosa, CA}}</ref><ref>{{cite journal|last1 = Henze| first1 = Niels|last2 = Rukzio| first2 = Enrico|last3 = Boll| first3 = Susanne| title= 100,000,000 Taps: Analysis and Improvement of Touch Performance in the Large|journal=Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services|year=2011|location = New York}}</ref><ref>{{cite journal|last = Parhi | first = Pekka | title = Target Size Study for One-Handed Thumb Use on Small Touchscreen Devices |journal=Proceedings of MobileHCI 2006 | year = 2006 | location = New York}}</ref> Users are subconsciously aware of this, and are also slightly slower, taking more time to select smaller targets, and any at the edges and corners.<ref>{{cite journal|last1 = Lee| first1 = Seungyons|last2 = Zhai| first2 = Shumin| title= The Performance of Touch Screen Soft Buttons|journal=Proceedings of the SIGCHI Conference on Human Factors in Computing Systems|year=2009|location = New York}}</ref>\n\nThis inaccuracy is a result of [[parallax]], visual acuity and the speed of the feedback loop between the eyes and fingers. The precision of the human finger alone is much, much higher than this, so when assistive technologies are provided such as on-screen magnifiers, users can move their finger (once in contact with the screen) with precision as small as 0.1&nbsp;mm.<ref>{{cite journal|last = B\u00e9rard | first = Fran\u00e7ois | title = Measuring the Linear and Rotational User Precision in Touch Pointing | journal = Proceedings of the 2012 ACM International Conference on Interactive Tabletops and Surfaces|year=2012|location = New York}}</ref>\n\n===Hand position, digit used and switching===\nUsers of handheld and portable touchscreen devices hold them in a variety of ways, and routinely change their method of holding and selection to suit the position and type of input. There are four basic types of handheld interaction:\n\n# Holding at least in part with both hands, tapping with a single thumb\n# Holding with one hand, tapping with the finger (or rarely, thumb) of another hand\n# Holding the device in one hand, and tapping with the thumb from that hand\n# Holding with two hands and tapping with both thumbs\n\nUse rates vary widely. While two-thumb tapping is encountered rarely (1-3%) for many general interactions, it is used for 41% of typing interaction.<ref>{{cite web|last = Hoober | first = Steven | url=http://uxmatters.com/mt/archives/2014/09/insights-on-switching-centering-and-gestures-for-touchscreens.php | title=Insights on Switching, Centering, and Gestures for Touchscreens | publisher=UXmatters | date = 2014-09-02 | accessdate=2014-08-24}}</ref>\n\nIn addition, devices are often placed on surfaces (desks or tables) and tablets especially are used in stands. The user may point, select or gesture in these cases with their finger or thumb, and also varies the use.<ref>{{cite web|last = Hoober | first = Steven | url=http://www.uxmatters.com/mt/archives/2013/02/how-do-users-really-hold-mobile-devices.php | title=How Do Users Really Hold Mobile Devices? | publisher=UXmatters | date = 2013-02-18 | accessdate=2014-08-24}}</ref>\n\n===Combined with haptics===\nTouchscreens are often used with [[haptic technology|haptic]] response systems. A common example of this technology is the vibratory feedback provided when a button on the touchscreen is tapped. Haptics are used to improve the user's experience with touchscreens by providing simulated tactile feedback, and can be designed to react immediately, partly countering on-screen response latency. Research from the University of Glasgow Scotland [Brewster, Chohan, and Brown 2007 and more recently Hogan] demonstrates that sample users reduce input errors (20%), increase input speed (20%), and lower their cognitive load (40%) when touchscreens are combined with haptics or tactile feedback [vs. non-haptic touchscreens].\n\n===\"Gorilla arm\"===\nExtended use of gestural interfaces without the ability of the user to rest their arm is referred to as \"gorilla arm.\"<ref>{{cite web|url=http://catb.org/jargon/html/G/gorilla-arm.html |title=gorilla arm |publisher=Catb.org |accessdate=2012-01-04}}</ref> It can result in fatigue, and even repetitive stress injury when routinely used in a work setting. Certain early pen-based interfaces required the operator to work in this position for much of the work day.<ref>{{cite web|url=http://gesturedesignblog.com/?page_id=19|title=Gesture Fatigue ruined light pens forever. Make sure it doesn\u2019t ruin your gesture design |publisher=Gesture Design Blog|accessdate=2014-08-23|archiveurl=https://web.archive.org/web/20150213011323/http://gesturedesignblog.com/?page_id=19|archivedate=2015-02-13|deadurl=yes}}</ref> Allowing the user to rest their hand or arm on the input device or a frame around it is a solution for this in many contexts. This phenomenon is often cited as a ''[[prima facie]]'' example of what not to do in ergonomics.\n\nUnsupported touchscreens are still fairly common in applications such as ATMs and data kiosks, but are not an issue as the typical user only engages for brief and widely spaced periods.<ref>{{cite web|author=David Pogue|date=January 3, 2013|url=https://www.scientificamerican.com/article.cfm?id=why-touch-screens-will-not-take-over|title=Why Touch Screens Will Not Take Over|work=[[Scientific American]]|accessdate=2013-01-06}}</ref>\n\n===Fingerprints===\n[[File:IPad with extensive fingerprints and smudges.jpg|thumb|Fingerprints and smudges on a tablet computer touchscreen]]\n\nTouchscreens can suffer from the problem of fingerprints on the display. This can be mitigated by the use of materials with [[optical coating]]s designed to reduce the visible effects of fingerprint oils, or [[oleophobic]] coatings as most of the modern smartphones, which lessen the actual amount of oil residue (which includes alcohol), or by installing a matte-finish anti-glare [[screen protector]], which creates a slightly roughened surface that does not easily retain smudges.\n\n==See also==\n{{div col|3}}\n*[[Dual-touchscreen]]\n*[[Pen computing]]\n*[[Energy harvesting]]\n*[[Flexible keyboard]]\n*[[Gestural interface]]\n*[[Graphics tablet]]\n*[[Graphics tablet-screen hybrid]]\n*[[Lock screen]]\n*[[List of Touch Solution manufacturers]]\n*[[Tablet computer|Tablet PC]]\n*[[Touch switch]]\n*[[Touchscreen remote control]]\n*[[Multi-touch]]\n*[[Omnitouch]]\n*[[SixthSense]]\n{{div col end}}\n\n==Notes==\n{{Reflist|colwidth=30em}}\n\n==References==\n{{refbegin}}\n*{{Cite journal |doi=10.1109/52.73754 |title=Touch screens now offer compelling uses |journal=IEEE Software |volume=8 |issue=2 |year=1991 |pages=93\u201394, 107 |last1=Shneiderman |first1=B. }}\n*{{Cite book |last=Potter |first=R. |last2=Weldon |first2=L. |lastauthoramp=yes |last3=Shneiderman |first3=B. |title=An experimental evaluation of three strategies |series=Proc. CHI'88 |location=Washington, DC |year=1988 |publisher=ACM Press |pages=27\u201332 }}\n*{{Cite book |last=Sears |first=A. |last2=Plaisant |first2=C. |lastauthoramp=yes |last3=Shneiderman |first3=B. |chapter=A new era for high precision touchscreens |title=Advances in Human-Computer Interaction |volume=3 |year=1992 |editor1-last=Hartson |editor1-first=R. |editor2-last=Hix |editor2-first=D. |location=Ablex, NJ |pages=1\u201333 }}\n*{{Cite journal |last=Sears |first=A. |lastauthoramp=yes |last2=Shneiderman |first2=B. |title=High precision touchscreen: Design strategies and comparison with a mouse |journal=Int. J. of Man-Machine Studies |volume=34 |issue=4 |year=1991 |pages=593\u2013613 |doi=10.1016/0020-7373(91)90037-8 }}\n{{refend}}\n\n*{{Cite journal |last=Holzinger |first=A. |title=Finger Instead of Mouse: Touch Screens as a means of enhancing Universal Access |journal=In: Carbonell, N.; Stephanidis C. (Eds): Universal Access, Lecture Notes in Computer Science |volume=2615 |year=2003 |pages=387\u2013397 |doi=10.1007/3-540-36572-9_30 |series=Lecture Notes in Computer Science |isbn=978-3-540-00855-2}}\n{{refend}}\n\n==External links==\n{{Commons category|Touchscreens}}\n{{Wiktionary|touch screen}}\n* [http://electronics.howstuffworks.com/question716.htm Howstuffworks] - How do touchscreen monitors know where you're touching?\n* [http://www.cammaxlimited.co.uk/what-are-the-different-types-of-touchscreen/ What are the different types of touchscreen technology]\n* [http://arstechnica.com/gadgets/2013/04/from-touch-displays-to-the-surface-a-brief-history-of-touchscreen-technology/ From touch displays to the surface: A brief history of touchscreen technology]\n* [http://ruetersward.com/biblio.html Annotated bibliography of references to handwriting recognition and pen computing]\n* [http://www.walkermobile.com/Touch_Technologies_Tutorial_Latest_Version.pdf Part 1: Fundamentals of Projected-Capacitive Touch Technology, Geoff Walker, June 2014]\n{{Basic computer components}}\n\n{{Authority control}}\n\n[[Category:American inventions]]\n[[Category:Touchscreens| ]]\n[[Category:Display devices]]"}]}}}}