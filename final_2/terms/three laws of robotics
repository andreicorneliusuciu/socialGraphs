{"batchcomplete":"","query":{"normalized":[{"from":"Three_Laws_of_Robotics","to":"Three Laws of Robotics"}],"pages":{"60136":{"pageid":60136,"ns":0,"title":"Three Laws of Robotics","revisions":[{"contentformat":"text/x-wiki","contentmodel":"wikitext","*":"[[Image:I Robot - Runaround.jpg|thumb|This cover of ''[[I, Robot]]'' illustrates the story \"Runaround\", the first to list all Three Laws of Robotics.]]{{Robotic laws}}\n'''The Three Laws of Robotics''' (often shortened to '''The Three Laws''' or known as '''Asimov's Laws''') are a set of rules devised by the [[science fiction]] author [[Isaac Asimov]]. The rules were introduced in his 1942 short story \"[[Runaround (story)|Runaround]]\", although they had been foreshadowed in a few earlier stories. The Three Laws, quoted as being from the \"Handbook of Robotics, 56th Edition, 2058 A.D.\", are:\n\n# A robot may not injure a human being or, through inaction, allow a human being to come to harm.\n# A robot must obey the orders <!-- Do not add \"to\" here: it's not in the source. -->{{sic|given it|expected=given to it|hide=y}}<!-- Do not add \"to\" here: it's not in the source. --> by human beings except where such orders would conflict with the First Law.\n# A robot must protect its own existence as long as such protection does not conflict with the First or Second Laws.<ref name=IROBOT />\n\nThese form an organizing principle and unifying theme for Asimov's [[robot]]ic-based fiction, appearing in his [[Robot series (Asimov)|''Robot'' series]], the stories linked to it, and his [[Lucky Starr series|''Lucky Starr'' series]] of [[young adult literature|young-adult fiction]]. The Laws are incorporated into almost all of the [[positronic brain|positronic robot]]s appearing in his fiction, and cannot be bypassed, being intended as a safety feature. Many of Asimov's robot-focused stories involve robots behaving in unusual and counter-intuitive ways as an unintended consequence of how the robot applies the Three Laws to the situation in which it finds itself. Other authors working in Asimov's fictional universe have adopted them and references, often [[parody|parodic]], appear throughout science fiction as well as in other genres.\n\nThe original laws have been altered and elaborated on by Asimov and other authors. Asimov himself made slight modifications to the first three in various books and short stories to further develop how robots would interact with humans and each other. In later fiction where robots had taken responsibility for government of whole planets and human civilizations, Asimov also added a fourth, or zeroth law, to precede the others:\n\n:0. A robot may not harm humanity, or, by inaction, allow humanity to come to harm.\n\nThe Three Laws, and the zeroth, have pervaded science fiction and are referred to in many books, films, and other media.\n\n==History==\nIn ''The Rest of the Robots'', published in 1964, Asimov noted that when he began writing in 1940 he felt that \"one of the stock plots of science fiction was&nbsp;... robots were created and destroyed their creator. Knowledge has its dangers, yes, but is the response to be a retreat from knowledge? Or is knowledge to be used as itself a barrier to the dangers it brings?\" He decided that in his stories robots would not \"turn stupidly on his creator for no purpose but to demonstrate, for one more weary time, the crime and punishment of [[Faust]].\"<ref>{{cite book| title=The Rest of the Robots| publisher=Doubleday| year=1964| isbn=0-385-09041-2| chapter=Introduction| author=Isaac Asimov}}</ref>\n\nOn May 3, 1939, Asimov attended a meeting of the [[Queens]] ([[New York (state)|New York]]) Science Fiction Society where he met [[Eando Binder|Ernest and Otto Binder]] who had recently published a short story [[I, Robot (short story)|\"I, Robot\"]] featuring a sympathetic robot named [[Adam Link]] who was misunderstood and motivated by love and honor. (This was the first of a series of ten stories; the next year \"Adam Link's Vengeance\" (1940) featured Adam thinking \"A robot must never kill a human, of his own free will.\")<ref>{{cite journal| authorlink=James Gunn (author)| last=Gunn| first=James| title=On Variations on a Robot| journal=[[Asimov's Science Fiction|IASFM]]|date=July 1980| pages=56\u201381}} Reprinted in {{cite book| title=Isaac Asimov: The Foundations of Science Fiction| year=1982| isbn=0-19-503060-5| author=James Gunn.| publisher=Oxford Univ. Pr.| location=Oxford u.a.}}</ref> Asimov admired the story. Three days later Asimov began writing \"my own story of a sympathetic and noble robot\", his 14th story.<ref>{{cite book| title=In Memory Yet Green| publisher=Doubleday| year=1979| first=Isaac| last=Asimov| isbn=0-380-75432-0| page=237}}</ref> Thirteen days later he took \"[[Robbie (short story)|Robbie]]\" to [[John W. Campbell]] the editor of ''[[Astounding (magazine)|Astounding Science-Fiction]]''. Campbell rejected it claiming that it bore too strong a resemblance to [[Lester del Rey]]'s \"[[Helen O'Loy]]\", published in December 1938; the story of a robot that is so much like a person that she falls in love with her creator and becomes his ideal wife.<ref>Asimov (1979), pp.236\u20138</ref> [[Frederik Pohl]] published \"Robbie\" in ''[[Astonishing Stories]]'' magazine the following year.<ref>Asimov (1979), p. 263.</ref>\n\nAsimov attributes the Three Laws to John W. Campbell, from a conversation that took place on 23 December 1940. Campbell claimed that Asimov had the Three Laws already in his mind and that they simply needed to be stated explicitly. Several years later Asimov's friend [[Randall Garrett]] attributed the Laws to a [[symbiosis|symbiotic]] partnership between the two men&nbsp;\u2013 a suggestion that Asimov adopted enthusiastically.<ref>Asimov (1979), pp. 285\u20137.</ref> According to his autobiographical writings Asimov included the First Law's \"inaction\" clause because of [[Arthur Hugh Clough]]'s poem \"The Latest Decalogue\", which includes the satirical lines \"Thou shalt not kill, but needst not strive / officiously to keep alive\".<ref>Asimov, Isaac (1979). In Memory Yet Green. Doubleday. Chapters 21 through 26 ISBN 0-380-75432-0.</ref>\n\nAlthough Asimov pins the creation of the Three Laws on one particular date, their appearance in his literature happened over a period. He wrote two robot stories with no explicit mention of the Laws, \"[[Robbie (short story)|Robbie]]\" and \"[[Reason (Asimov)|Reason]]\". He assumed, however, that robots would have certain inherent safeguards. \"[[Liar! (short story)|Liar!]]\", his third robot story, makes the first mention of the First Law but not the other two. All three laws finally appeared together in \"[[Runaround (story)|Runaround]]\". When these stories and several others were compiled in the anthology ''[[I, Robot]]'', \"Reason\" and \"Robbie\" were updated to acknowledge all the Three Laws, though the material Asimov added to \"Reason\" is not entirely consistent with the Three Laws as he described them elsewhere.<ref>{{cite book| last=Patrouch| first=Joseph F.| title=The Science Fiction of Isaac Asimov| publisher=Doubleday| year=1974| isbn=0-385-08696-2| page=42}}</ref> In particular the idea of a robot protecting human lives when it does not believe those humans truly exist is at odds with Elijah Baley's reasoning, as described [[#Ambiguities and loopholes|below]].\n\nDuring the 1950s Asimov wrote a series of science fiction novels expressly intended for young-adult audiences. Originally his publisher expected that the novels could be adapted into a long-running television series, something like ''[[The Lone Ranger]]'' had been for radio. Fearing that his stories would be adapted into the \"uniformly awful\" programming he saw flooding the television channels<ref>Asimov (1979), p. 620.</ref> Asimov decided to publish the [[Lucky Starr series|''Lucky Starr'']] books under the [[pseudonym]] \"Paul French\". When plans for the television series fell through, Asimov decided to abandon the pretence; he brought the Three Laws into ''Lucky Starr and the Moons of Jupiter'', noting that this \"was a dead giveaway to Paul French's identity for even the most casual reader\".<ref>{{cite book| title=In Joy Still Felt| publisher=Doubleday| year=1980| isbn=0-385-15544-1| last= Asimov| first=Isaac| page=61}}</ref>\n\nIn his short story [[Evidence (Asimov)|\"Evidence\"]] Asimov lets his recurring character [[Susan Calvin|Dr. Susan Calvin]] expound a [[morality|moral]] basis behind the Three Laws. Calvin points out that human beings are typically expected to refrain from harming other human beings (except in times of extreme duress like war, or to save a greater number) and this is equivalent to a robot's First Law. Likewise, according to Calvin, society expects individuals to obey instructions from recognized authorities such as doctors, teachers and so forth which equals the Second Law of Robotics. Finally humans are typically expected to avoid harming themselves which is the Third Law for a robot.\n\nThe plot of \"Evidence\" revolves around the question of telling a human being apart from a robot constructed to appear human&nbsp;\u2013 Calvin reasons that if such an individual obeys the Three Laws he may be a robot or simply \"a very good man\". Another character then asks Calvin if robots are very different from human beings after all. She replies, \"Worlds different. Robots are essentially decent.\"\n\nAsimov later wrote that he should not be praised for creating the Laws, because they are \"obvious from the start, and everyone is aware of them subliminally. The Laws just never happened to be put into brief sentences until I managed to do the job. The Laws apply, as a matter of course, to every tool that human beings use\",<ref name=\"asimov198111\">{{cite news | url=https://archive.org/stream/1981-11-compute-magazine/Compute_Issue_018_1981_Nov#page/n19/mode/2up | title=The Three Laws | work=Compute! | date=November 1981 | accessdate=26 October 2013 | author=Asimov, Isaac | page=18}}</ref> and \"analogues of the Laws are implicit in the design of almost all tools, robotic or not\":<ref>{{cite book |last= Asimov |first=Isaac |title= Robot Visions|date= 12 April 2001|publisher= Gollancz|isbn= 978-1-85798-336-4 }}</ref>\n\n#Law 1: A tool must not be unsafe to use. [[Hammer]]s have handles and [[screwdriver]]s have hilts to help increase grip. It is of course possible for a person to injure himself with one of these tools, but that injury would only be due to his incompetence, not the design of the tool.\n#Law 2: A tool must perform its function efficiently unless this would harm the user. This is the entire reason [[ground-fault circuit interrupter]]s exist. Any running tool will have its power cut if a circuit senses that some current is not returning to the neutral wire, and hence might be flowing through the user. The safety of the user is paramount.\n#Law 3: A tool must remain intact during its use unless its destruction is required for its use or for safety. For example, [[Dremel]] disks are designed to be as tough as possible without breaking unless the job requires it to be spent. Furthermore, they are designed to break at a point before the shrapnel velocity could seriously injure someone (other than the eyes, though safety glasses should be worn at all times anyway).\n\nAsimov believed that, ideally, humans would also follow the Laws:{{r|asimov198111}}\n\n{{quote|I have my answer ready whenever someone asks me if I think that my Three Laws of Robotics will actually be used to govern the behavior of robots, once they become versatile and flexible enough to be able to choose among different courses of behavior.\n\nMy answer is, \"Yes, the Three Laws are the only way in which rational human beings can deal with robots\u2014or with anything else.\"\n\n\u2014But when I say that, I always remember (sadly) that human beings are not always rational.}}\n\n==Alterations==\n\n===By Asimov===\nAsimov's stories test his Three Laws in a wide variety of circumstances leading to proposals and rejection of modifications. Science fiction scholar [[James Gunn (author)|James Gunn]] writes in 1982, \"The Asimov robot stories as a whole may respond best to an analysis on this basis: the ambiguity in the Three Laws and the ways in which Asimov played twenty-nine variations upon a theme\".<ref>Gunn (1982).</ref> While the original set of Laws provided inspirations for many stories, Asimov introduced modified versions from time to time.\n\n====First Law modified====\nIn \"[[Little Lost Robot]]\" several NS-2, or \"Nestor\", robots are created with only part of the First Law. It reads:\n\n{{quote|1. A robot may not harm a human being.}}\n\nThis modification is motivated by a practical difficulty as robots have to work alongside human beings who are exposed to low doses of radiation. Because their [[positronic brain]]s are highly sensitive to [[gamma ray]]s the robots are rendered inoperable by doses reasonably safe for humans. The robots are being destroyed attempting to rescue the humans who are in no actual danger but \"might forget to leave\" the irradiated area within the exposure time limit. Removing the First Law's \"inaction\" clause solves this problem but creates the possibility of an even greater one: a robot could initiate an action that would harm a human (dropping a heavy weight and failing to catch it is the example given in the text), knowing that it was capable of preventing the harm and then decide not to do so.<ref name=\"IROBOT\">{{cite book|last=Asimov|first=Isaac|title=I, Robot|date=1950}}</ref>\n\n[[Gaia (Foundation universe)|Gaia]] is a planet with [[collective intelligence]] in the [[Foundation series|''Foundation'']] which adopts a law similar to the First Law, and the Zeroth Law, as its philosophy:\n\n{{quote|Gaia may not harm life or allow life to come to harm.}}\n\n====Zeroth Law added====\nAsimov once added a \"[[Zero-based numbering|Zeroth]] Law\"\u2014so named to continue the pattern where lower-numbered laws supersede the higher-numbered laws\u2014stating that a robot must not harm humanity. The robotic character [[R. Daneel Olivaw]] was the first to give the Zeroth Law a name in the novel ''[[Robots and Empire]]'';<ref name=\"BBCAsimov\">{{cite web|title=Isaac Asimov|url=http://www.bbc.co.uk/dna/h2g2/A42253922|publisher=BBC|accessdate=11 November 2010}}</ref> however, the character [[Susan Calvin]] articulates the concept in the short story \"[[The Evitable Conflict]]\".\n\nIn the final scenes of the novel ''Robots and Empire'', [[R. Giskard Reventlov]] is the first robot to act according to the Zeroth Law. Giskard is [[telepathic]], like the robot Herbie in the short story \"[[Liar! (short story)|Liar!]]\", and tries to apply the Zeroth Law through his understanding of a more subtle concept of \"harm\" than most robots can grasp.<ref name=\"SC1\">{{cite news |title=Sci-fi writer Isaac Asimov |url=http://archive.thedailystar.net/campus/2007/07/05/autprofile.htm |work=Campus Star |publisher=[[The Daily Star (Bangladesh)|The Daily Star]] |date=29 July 2007 |accessdate=7 August 2016 |quote=Only highly advanced robots (such as Daneel and Giskard) could comprehend this law.}}</ref> However, unlike Herbie, Giskard grasps the philosophical concept of the Zeroth Law allowing him to harm individual human beings if he can do so in service to the abstract concept of humanity. The Zeroth Law is never programmed into Giskard's brain but instead is a rule he attempts to comprehend through pure [[metacognition]]. Though he fails &ndash; it ultimately destroys his positronic brain as he is not certain whether his choice will turn out to be for the ultimate good of humanity or not &ndash; he gives his successor R. Daneel Olivaw his telepathic abilities. Over the course of many thousands of years Daneel adapts himself to be able to fully obey the Zeroth Law. As Daneel formulates it, in the novels ''[[Foundation and Earth]]'' and ''[[Prelude to Foundation]]'', the Zeroth Law reads:\n\n{{quote|A robot may not harm humanity, or, by inaction, allow humanity to come to harm.}}\n\nA condition stating that the Zeroth Law must not be broken was added to the original Three Laws, although Asimov recognized the difficulty such a law would pose in practice.\n\n{{quote|\nTrevize frowned. \"How do you decide what is injurious, or not injurious, to humanity as a whole?\"\n\n\"Precisely, sir,\" said Daneel. \"In theory, the Zeroth Law was the answer to our problems. In practice, we could never decide. A human being is a concrete object. Injury to a person can be estimated and judged. Humanity is an abstraction.\"|Foundation and Earth}}\n\nA translator incorporated the concept of the Zeroth Law into one of Asimov's novels before Asimov himself made the law explicit.<ref name=\"Br\u00e9card\" /> Near the climax of ''[[The Caves of Steel]]'', [[Elijah Baley]] makes a bitter comment to himself thinking that the First Law forbids a robot from harming a human being. He determines that it must be so unless the robot is clever enough to comprehend that its actions are for humankind's long-term good. In Jacques Br\u00e9card's 1956 [[French language|French]] translation entitled ''[[:fr:Les Cavernes d'acier|Les Cavernes d'acier]]'' Baley's thoughts emerge in a slightly different way:\n\n{{quote|\"A robot may not harm a human being, unless he finds a way to prove that ultimately the harm done would benefit humanity in general!\"<ref name=\"Br\u00e9card\">{{cite book| last=Asimov| first=Isaac| title=The Caves of Steel| publisher=Doubleday| year=1952}}, translated by Jacques Br\u00e9card as {{cite book| title=[[:fr:Les Cavernes d'acier|Les Cavernes d'acier]]| publisher=J'ai Lu Science-fiction| year=1975| isbn=2-290-31902-3}}</ref>}}\n\n====Removal of the Three Laws====\nAsimov portrayed robots that disregard the Three Laws entirely thrice during his writing career. The first case was a [[Vignette (literature)|short-short story]] entitled \"[[First Law]]\" and is often considered an insignificant \"tall tale\"<ref>Patrouch (1974), p. 50.</ref> or even [[apocrypha]]l.<ref>Gunn (1980); reprinted in Gunn (1982), p. 69.</ref> On the other hand, the short story \"[[Cal (short story)|Cal]]\" (from the collection ''[[Gold (Asimov)|Gold]]''), told by a first-person robot narrator, features a robot who disregards the Three Laws because he has found something far more important\u2014he wants to be a writer. Humorous, partly autobiographical and unusually experimental in style, \"Cal\" has been regarded as one of ''Gold'''s strongest stories.<ref>{{cite web| last=Jenkins| first=John H.| work=Jenkins' Spoiler-Laden Guide to Isaac Asimov| url=http://preem.tejat.net/~tseng/Asimov/Stories/Story419.html| year=2002| accessdate = 2009-06-26| title=Review of \"Cal\"}}</ref> The third is a short story entitled \"[[Sally (Asimov)|Sally]]\" in which cars fitted with positronic brains are apparently able to harm and kill humans in disregard of the First Law. However, aside from the positronic brain concept, this story does not refer to other robot stories and may not be set in the same [[continuity (fiction)|continuity]].\n\nThe title story of the ''[[Robot Dreams]]'' collection portrays LVX-1, or \"Elvex\", a robot who enters a state of unconsciousness and dreams thanks to the unusual [[fractal]] construction of his positronic brain. In his dream the first two Laws are absent and the Third Law reads \"A robot must protect its own existence\".<ref name=\"RDA1\">{{cite book|last=Asimov|first=Isaac|title=Robot Dreams|year=1986|authorlink=Isaac Asimov|accessdate=11 November 2010|url=https://web.archive.org/web/20120316134042/http://www.tcnj.edu/~miranda/classes/topics/reading/asimov.pdf|quote=\u201cBut you quote it in incomplete fashion. The Third Law is \u2018A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.\u2019 \u201d \u201cYes, Dr. Calvin. That is the Third Law in reality, but in my dream, the Law ended with the word \u2018existence\u2019. There was no mention of the First or Second Law.\u201d}}</ref>\n\nAsimov took varying positions on whether the Laws were optional: although in his first writings they were simply carefully engineered safeguards, in later stories Asimov stated that they were an inalienable part of the mathematical foundation underlying the positronic brain. Without the basic theory of the Three Laws the fictional scientists of Asimov's universe would be unable to design a workable brain unit. This is historically consistent: the occasions where roboticists modify the Laws generally occur early within the stories' chronology and at a time when there is less existing work to be re-done. In \"Little Lost Robot\" Susan Calvin considers modifying the Laws to be a terrible idea, although possible,<ref name=\"BBC2\">{{cite web|title='The Complete Robot' by Isaac Asimov|url=http://www.bbc.co.uk/dna/h2g2/A455898|publisher=BBC|accessdate=11 November 2010|date=3 November 2000|quote=The answer is that it had had its First Law modified}}</ref> while centuries later Dr. Gerrigel in ''[[The Caves of Steel]]'' believes it to be impossible.\n\nThe character Dr. Gerrigel uses the term \"Asenion\" to describe robots programmed with the Three Laws. The robots in Asimov's stories, being Asenion robots, are incapable of knowingly violating the Three Laws but, in principle, a robot in science fiction or in the real world could be non-Asenion. \"Asenion\" is a misspelling of the name Asimov which was made by an editor of the magazine ''Planet Stories.''<ref>Asimov (1979), pp. 291\u20132.</ref> Asimov used this obscure variation to insert himself into ''The Caves of Steel'' just like he referred to himself as \"Azimuth or, possibly, Asymptote\" in ''[[Thiotimoline]] to the Stars'', in much the same way that [[Vladimir Nabokov]] appeared in ''[[Lolita]]'' [[anagram]]matically disguised as \"Vivian Darkbloom\".\n\nCharacters within the stories often point out that the Three Laws, as they exist in a robot's mind, are not the written versions usually quoted by humans but abstract mathematical concepts upon which a robot's entire developing consciousness is based. This concept is largely fuzzy and unclear in earlier stories depicting very rudimentary robots who are only programmed to comprehend basic physical tasks, where the Three Laws act as an overarching safeguard, but by the era of ''The Caves of Steel'' featuring robots with human or beyond-human intelligence the Three Laws have become the underlying basic ethical worldview that determines the actions of all robots.\n\n===By other authors===\n\n====Roger MacBride Allen's trilogy====\nIn the 1990s, [[Roger MacBride Allen]] wrote a trilogy which was set within Asimov's fictional universe. Each title has the prefix \"Isaac Asimov's\" as Asimov had approved Allen's outline before his death.{{citation needed|date=June 2011}} These three books, ''[[Isaac Asimov's Caliban|Caliban]]'', ''[[Isaac Asimov's Inferno|Inferno]]'' and ''[[Isaac Asimov's Utopia|Utopia]]'', introduce a new set of the Three Laws. The so-called New Laws are similar to Asimov's originals with the following differences: the First Law is modified to remove the \"inaction\" clause, the same modification made in \"Little Lost Robot\"; the Second Law is modified to require cooperation instead of obedience; the Third Law is modified so it is no longer superseded by the Second (i.e., a \"New Law\" robot cannot be ordered to destroy itself); finally, Allen adds a Fourth Law which instructs the robot to do \"whatever it likes\" so long as this does not conflict with the first three laws. The philosophy behind these changes is that \"New Law\" robots should be partners rather than slaves to humanity, according to [[Fredda Leving]], who designed these [[New Law Robots]]. According to the first book's introduction, Allen devised the New Laws in discussion with Asimov himself. However, the ''Encyclopedia of Science Fiction'' says that \"With permission from Asimov, Allen rethought the Three Laws and developed a new set,\".<ref name=\"EoSF1\">{{cite book|title=Encyclopedia of science fiction|year=2005|publisher=Infobase Publishing|isbn=978-0-8160-5924-9|url=https://books.google.com/books?id=icA3oLIZEeMC&pg=PA7&dq=Isaac+Asimov%27s+Caliban+introduction#v=onepage&q&f=false|author=Don D'Ammassa|accessdate=11 November 2010|page=7|chapter=Allen, Roger MacBride}}</ref>\n\n====Jack Williamson's ''With Folded Hands''====\n[[Jack Williamson]]'s novelette ''[[With Folded Hands]]'' (1947), later rewritten as the novel ''The Humanoids,'' deals with robot servants whose prime directive is \"To Serve and Obey, And Guard Men From Harm.\" While Asimov's robotic laws are meant to protect humans from harm, the robots in Williamson's story have taken these instructions to the extreme; they protect humans from everything, including unhappiness, stress, unhealthy lifestyle and all actions that could be potentially dangerous. All that is left for humans to do is to sit with folded hands.<ref>{{cite web|url=http://www.umich.edu/~engb415/literature/cyberzach/Williamson/human.html |title=The Humanoids |publisher=Umich.edu |date= |accessdate=2015-03-28}}</ref>\n\n====''Foundation'' sequel trilogy====\nIn the officially licensed ''Foundation'' sequels ''[[Foundation's Fear]]'', ''[[Foundation and Chaos]]'' and ''[[Foundation's Triumph]]'' (by [[Gregory Benford]], [[Greg Bear]] and [[David Brin]] respectively) the future [[Galactic Empire (Asimov)|Galactic Empire]] is seen to be controlled by a conspiracy of humaniform robots who follow the Zeroth Law and led by [[R. Daneel Olivaw]].\n\nThe Laws of Robotics are portrayed as something akin to a human [[religion]], and referred to in the language of the [[Protestant Reformation]], with the set of laws containing the Zeroth Law known as the \"Giskardian Reformation\" to the original \"Calvinian Orthodoxy\" of the Three Laws. Zeroth-Law robots under the control of R. Daneel Olivaw are seen continually struggling with \"First Law\" robots who deny the existence of the Zeroth Law, promoting agendas different from Daneel's.<ref name=\"TMATWilkinson1\">{{cite book|title=The muse as therapist: a new poetic paradigm for psychotherapy|year=2009|publisher=Karnac Books|isbn=978-1-85575-595-6|url=https://books.google.com/books?id=rjhWPnUGexQC&pg=PA22&dq=R.+Daneel+Olivaw+Giskardian+Reformation#v=onepage&q=R.%20Daneel%20Olivaw%20Giskardian%20Reformation&f=false|author=Heward Wilkinson|accessdate=11 November 2010|pages=22\u201323}}</ref> Some of these agendas are based on the first clause of the First Law (\"A robot may not injure a human being...\") advocating strict non-interference in human politics to avoid unwittingly causing harm. Others are based on the second clause (\"...or, through inaction, allow a human being to come to harm\") claiming that robots should openly become a [[Dictatorship|dictatorial]] government to protect humans from all potential conflict or disaster.\n\nDaneel also comes into conflict with a robot known as R. Lodovic Trema whose positronic brain was infected by a rogue [[artificial intelligence|AI]] \u2014 specifically, a simulation of the long-dead [[Voltaire]] \u2014 which consequently frees Trema from the Three Laws. Trema comes to believe that humanity should be free to choose its own future. Furthermore, a small group of robots claims that the Zeroth Law of Robotics itself implies a higher Minus One Law of Robotics:\n\n{{quote|A robot may not harm [[sentience]] or, through inaction, allow sentience to come to harm.}}\n\nThey therefore claim that it is morally indefensible for Daneel to ruthlessly sacrifice robots and [[extraterrestrial life|extraterrestrial]] sentient life for the benefit of humanity. None of these reinterpretations successfully displace Daneel's Zeroth Law \u2014 though ''Foundation's Triumph'' hints that these robotic factions remain active as fringe groups up to the time of the novel [[Foundation (Isaac Asimov novel)|''Foundation'']].<ref name=\"TMATWilkinson1\" />\n\nThese novels take place in a future dictated by Asimov to be free of obvious robot presence and surmise that R. Daneel's secret influence on history through the millennia has prevented both the rediscovery of [[positronic brain]] technology and the opportunity to work on sophisticated intelligent machines. This lack of rediscovery and lack of opportunity makes certain that the superior physical and intellectual power wielded by intelligent machines remains squarely in the possession of robots obedient to some form of the Three Laws.<ref name=\"TMATWilkinson1\" /> That R. Daneel is not entirely successful at this becomes clear in a brief period when scientists on [[Trantor]] develop \"[[Trantor#Food production|''tiktoks'']]\" \u2014 simplistic programmable machines akin to real\u2013life modern robots and therefore lacking the Three Laws. The robot conspirators see the Trantorian tiktoks as a massive threat to social stability, and their plan to eliminate the tiktok threat forms much of the plot of ''Foundation's Fear''.\n\nIn ''Foundation's Triumph'' different robot factions interpret the Laws in a wide variety of ways, seemingly ringing every possible permutation upon the Three Laws' ambiguities.\n\n====Robot Mystery series====\nSet between ''[[The Robots of Dawn]]'' and ''[[Robots and Empire]]'', [[Mark W. Tiedemann]]'s ''Robot Mystery'' trilogy updates the ''Robot''\u2013''Foundation'' saga with robotic minds housed in computer mainframes rather than humanoid bodies.{{clarify|not sure of the significance of this to the article - needs explaining via a reliable source|date=June 2011}} The 2002 Aurora novel has robotic characters debating the moral implications of harming cyborg lifeforms who are part artificial and part biological.<ref name=\"IAATiedemann1\">{{cite book|title=Isaac Asimov's Aurora (ebook)|publisher=Byron Press Visual Publications|author=MARK W. TIEDEMANN|page=558|quote=In short,\" Bogard said, \"not all people are human}}</ref>\n\nOne should not neglect Asimov's own creations in these areas such as the Solarian \"viewing\" technology and the machines of ''[[The Evitable Conflict]]'' originals that Tiedemann acknowledges. ''Aurora'', for example, terms the Machines \"the first RIs, really\". In addition the ''Robot Mystery'' series addresses the problem of [[nanotechnology]]:<ref name=\"tiedemann\">{{cite web| url=http://www.sffworld.com/interview/94p0.html| title=Interview with Mark Tiedemann| publisher=Science Fiction and Fantasy World| date=16 August 2002| accessdate = 2006-06-12}}</ref> building a positronic brain capable of reproducing human cognitive processes requires a high degree of miniaturization, yet Asimov's stories largely overlook the effects this miniaturization would have in other fields of technology. For example, the police department card-readers in ''The Caves of Steel'' have a capacity of only a few kilobytes per square centimeter of storage medium. ''Aurora'', in particular, presents a sequence of historical developments which explains the lack of nanotechnology \u2014 a partial [[retcon]], in a sense, of Asimov's timeline.\n\n====Additional laws====\nThere are three Fourth Laws written by authors other than Asimov. The 1974 [[Lyuben Dilov]] novel, ''Icarus's Way'' (a.k.a., ''The Trip of Icarus'') introduced a Fourth Law of robotics:\n\n{{quote|A robot must establish its identity as a robot in all cases.}}\n\nDilov gives reasons for the fourth safeguard in this way: \"The last Law has put an end to the expensive aberrations of designers to give psychorobots as humanlike a form as possible. And to the resulting misunderstandings...\"<ref>{{cite book\n| last = Dilov\n| first = Lyuben (aka Lyubin, Luben or Liuben)\n| authorlink = Lyuben Dilov\n| title = \u041f\u044a\u0442\u044f\u0442 \u043d\u0430 \u0418\u043a\u0430\u0440\n| year = 2002\n| publisher = \u0417\u0430\u0445\u0430\u0440\u0438 \u0421\u0442\u043e\u044f\u043d\u043e\u0432\n| isbn = 954-739-338-3}}</ref>\n\nA fifth law was introduced by [[Nikola Kesarovski]] in his short story \"The Fifth Law of Robotics\". This fifth law says:\n\n{{quote|A robot must know it is a robot.}}\n\nThe plot revolves around a murder where the forensic investigation discovers that the victim was killed by a hug from a humaniform robot. The robot violated both the First Law and Dilov's Fourth Law (assumed in Kesarovksi's universe to be the valid one) because it did not establish for itself that it was a robot.<ref>{{cite book\n| last = \u041a\u0435\u0441\u0430\u0440\u043e\u0432\u0441\u043a\u0438\n| first = \u041d\u0438\u043a\u043e\u043b\u0430\n| authorlink = Nikola Kesarovski\n| title = \u041f\u0435\u0442\u0438\u044f\u0442 \u0437\u0430\u043a\u043e\u043d\n| year = 1983\n| publisher = \u041e\u0442\u0435\u0447\u0435\u0441\u0442\u0432\u043e\n| isbn = }}</ref> The story was reviewed by [[Valentin D. Ivanov]] in SFF review webzine [[The Portal]].<ref>[http://sffportal.net/2011/06/lawful-little-country-the-bulgarian-laws-of-robotics/#more-2376 Lawful Little Country: The Bulgarian Laws of Robotics | The Portal<!-- Bot generated title -->]</ref>\n\nFor the 1986 tribute anthology, ''[[Foundation's Friends]],'' [[Harry Harrison (writer)|Harry Harrison]] wrote a story entitled, \"The Fourth Law of Robotics\". This Fourth Law states:\n\n{{quote|A robot must reproduce. As long as such reproduction does not interfere with the First or Second or Third Law.}}\n\nIn the book a robot rights activist, in an attempt to liberate robots, builds several equipped with this Fourth Law. The robots accomplish the task laid out in this version of the Fourth Law by building new robots who view their creator robots as parental figures.<ref name=\"HHThefourthlaw1\">{{cite book|last=Harrison|first=Harry|title=The Fourth Law of Robotics|year=1989|authorlink=Harry Harrison (writer)|pages=7\u20138|quote=A robot must reproduce. As long as such reproduction does not interfere with the First or Second or Third Law}}</ref>\n\nIn reaction to the 2004 Will Smith [[I, Robot (film)|film adaptation of ''I, Robot'']], humorist and graphic designer Mark Sottilaro farcically declared the Fourth Law of Robotics to be \"When turning evil, display a red indicator light.\" The red light indicated the wireless uplink to the manufacturer is active, first seen during a software update and later on \"Evil\" robots taken over by the manufacturer's positronic superbrain.\n\nIn 2013 Hutan Ashrafian, proposed an additional law that for the first time considered the role of artificial intelligence-on-artificial intelligence or the relationship between robots themselves \u2013 the so-called AIonAI law.<ref>{{cite journal |last= Ashrafian|first= Hutan| year= 2014|title= AIonAI: A Humanitarian Law of Artificial Intelligence and Robotics|url= http://link.springer.com/article/10.1007%2Fs11948-013-9513-9#page-1|journal= Science and Engineering Ethics|volume= 21|issue= 1|pages= 29\u201340|publisher= Springer| doi= 10.1007/s11948-013-9513-9|pmid= 24414678|accessdate=20 January 2014}}</ref> This sixth law states:\n\n{{quote|All robots endowed with comparable human reason and conscience should act towards one another in a spirit of brotherhood.}}\n\nIn [[Karl Schroeder]]'s ''Lockstep'' (2014) a character reflects that robots \"probably had multiple layers of programming to keep [them] from harming anybody. Not three laws, but twenty or thirty.\"\n\n== Ambiguities and loopholes ==\n\n===Unknowing breach of the laws===\nIn ''The Naked Sun'', [[Elijah Baley]] points out that the Laws had been deliberately misrepresented because robots could ''unknowingly'' break any of them. He restated the first law as \"A robot may do nothing that, ''to its knowledge,'' will harm a human being; nor, through inaction, ''knowingly'' allow a human being to come to harm.\" This change in wording makes it clear that robots can become the tools of murder, provided they not be aware of the nature of their tasks; for instance being ordered to add something to a person's food, not knowing that it is poison. Furthermore, he points out that a clever criminal could divide a task among multiple robots so that no individual robot could recognize that its actions would lead to harming a human being.<ref name=\"TNSPoison\">{{cite book|last=Asimov|first=Isaac|title=The Naked Sun (ebook)|year=1956\u20131957|page=233|quote=... one robot poison an arrow without knowing it was using poison, and having a second robot hand the poisoned arrow to the boy ...}}</ref> ''The Naked Sun'' complicates the issue by portraying a decentralized, planetwide communication network among Solaria's millions of robots meaning that the criminal mastermind could be located anywhere on the planet.\n\nBaley furthermore proposes that the Solarians may one day use robots for military purposes. If a spacecraft was built with a positronic brain and carried neither humans nor the life-support systems to sustain them, then the ship's robotic intelligence could naturally assume that all other spacecraft were robotic beings. Such a ship could operate more responsively and flexibly than one crewed by humans, could be armed more heavily and its robotic brain equipped to slaughter humans of whose existence it is totally ignorant.<ref name=\"TNSSpaceship\">{{cite book|last=Asimov|first=Isaac|title=The Naked Sun (ebook)|year=1956\u20131957|page=240|quote=But a spaceship that was equipped with its own positronic brain would cheerfully attack any ship it was directed to attack, it seems to me. It would naturally assume all other ships were unmanned}}</ref> This possibility is referenced in ''[[Foundation and Earth]]'' where it is discovered that the Solarians possess a strong police force of unspecified size that has been programmed to identify only the Solarian race as human.\n\n===Ambiguities resulting from lack of definition===\nThe Laws of Robotics presume that the terms \"human being\" and \"robot\" are understood and well defined. In some stories this presumption is overturned.\n\n====Definition of \"human being\"====\n\nThe [[Solaria]]ns create robots with the Three Laws but with a warped meaning of \"human\". Solarian robots are told that only people speaking with a Solarian accent are human. This enables their robots to have no ethical dilemma in harming non-Solarian human beings (and are specifically programmed to do so). By the time period of ''[[Foundation and Earth]]'' it is revealed that the Solarians have genetically modified themselves into a distinct species from humanity \u2014 becoming hermaphroditic<ref>{{cite web|title=Foundation and Earth (1986)|url=http://www.gotterdammerung.org/books/isaac-asimov/foundation-and-earth.html|publisher=gotterdammerung.org|accessdate=11 November 2010|author=Branislav L. Slantchev}}</ref> and [[telekinesis|telekinetic]] and containing biological organs capable of individually powering and controlling whole complexes of robots. The robots of Solaria thus respected the Three Laws only with regard to the \"humans\" of Solaria. It is unclear whether all the robots had such definitions, since only the overseer and guardian robots were shown explicitly to have them. In \"Robots and Empire\", the lower class robots were instructed by their overseer about whether certain creatures are human or not.\n\nAsimov addresses the problem of humanoid robots (\"[[android (robot)|android]]s\" in later parlance) several times. The novel ''[[Robots and Empire]]'' and the short stories \"[[Evidence (Asimov)|Evidence]]\" and \"The Tercentenary Incident\" describe robots crafted to fool people into believing that the robots are human.<ref name=\"ROBANDEMP1\">{{cite book|last=Asimov|first=Isaac|title=Robots and Empire|publisher=Doubleday books|isbn=0-385-19092-1|authorlink=Isaac Asimov|page=151|quote=although the woman looked as human as Daneel did, she was just as nonhuman}}</ref> On the other hand, \"[[The Bicentennial Man]]\" and \"[[\u2014That Thou Art Mindful of Him]]\" explore how the robots may change their interpretation of the Laws as they grow more sophisticated. [[Gwendoline Butler]] writes in ''A Coffin for the Canary'' \"Perhaps we are robots. Robots acting out the last Law of Robotics... To tend towards the human.\"<ref>{{cite book| last=Butler| first=Gwendoline| title=A Coffin for the Canary| publisher=Black Dagger Crime| year=2001| isbn=0-7540-8580-5}}</ref> In ''[[The Robots of Dawn]]'', [[Elijah Baley]] points out that the use of humaniform robots as the first wave of settlers on new Spacer worlds may lead to the robots seeing themselves as the true humans, and deciding to keep the worlds for themselves rather than allow the Spacers to settle there.\n\n\"\u2014That Thou Art Mindful of Him\", which Asimov intended to be the \"ultimate\" probe into the Laws' subtleties,<ref>Gunn (1980); reprinted in Gunn (1982), p. 73.</ref> finally uses the Three Laws to conjure up the very \"Frankenstein\" scenario they were invented to prevent. It takes as its concept the growing development of robots that mimic non-human living things and given programs that mimic simple animal behaviours which do not require the Three Laws. The presence of a whole range of robotic life that serves the same purpose as organic life ends with two humanoid robots concluding that organic life is an unnecessary requirement for a truly logical and self-consistent definition of \"humanity\", and that since they are the most advanced thinking beings on the planet \u2014 they are therefore the only two true humans alive and the Three Laws only apply to themselves. The story ends on a sinister note as the two robots enter hibernation and await a time when they will conquer the Earth and subjugate biological humans to themselves; an outcome they consider an inevitable result of the \"Three Laws of Humanics\".<ref name=\"TCRMindful1\">{{cite book|last=Asimov|first=Isaac|title=The Complete Robot|year=1982|publisher=Nightfall, Inc.|authorlink=Isaac Asimov|page=611|chapter=... That Thou Art Mindful Of Him}}</ref>\n\nThis story does not fit within the overall sweep of the ''Robot'' and [[Foundation Series|''Foundation'' series]]; if the George robots ''did'' take over Earth some time after the story closes the later stories would be either redundant or impossible. Contradictions of this sort among Asimov's fiction works have led scholars to regard the ''Robot'' stories as more like \"the Scandinavian sagas or the Greek legends\" than a unified whole.<ref>Gunn (1982), pp. 77\u20138.</ref>\n\nIndeed, Asimov describes \"\u2013That Thou Art Mindful of Him\" and \"Bicentennial Man\" as two opposite, parallel futures for robots that obviate the Three Laws as robots come to consider themselves to be humans: one portraying this in a positive light with a robot joining human society, one portraying this in a negative light with robots supplanting humans.<ref name=\"TCRBicentennial\">{{cite book|last=Asimov|first=Isaac|title=The Complete Robot|year=1982|publisher=Nightfall, Inc.|authorlink=Isaac Asimov|page=658|chapter=The Bicentennial Man}}</ref> Both are to be considered alternatives to the possibility of a robot society that continues to be driven by the Three Laws as portrayed in the ''Foundation'' series.{{According to whom|date=December 2010}} Indeed, in ''Positronic Man'', the novelization of \"Bicentennial Man\", Asimov and his co\u2013writer [[Robert Silverberg]] imply that in the future where Andrew Martin exists his influence causes humanity to abandon the idea of independent, sentient humanlike robots entirely, creating an utterly different future from that of ''Foundation''.{{According to whom|date=December 2010}}\n\nIn ''[[Lucky Starr and the Rings of Saturn]]'', a novel unrelated to the ''Robot'' series but featuring robots programmed with the Three Laws, John Bigman Jones is almost killed by a Sirian robot on orders of its master. The society of Sirius is eugenically bred to be uniformly tall and similar in appearance, and as such, said master is able to convince the robot that the much shorter Bigman, is, in fact, not a human being.\n\n====Definition of \"robot\"====\n\nAs noted in \"The Fifth Law of Robotics\" by [[Nikola Kesarovski]], \"A robot must know it is a robot\": it is presumed that a robot has a definition of the term or a means to apply it to its own actions. Nikola Kesarovski played with this idea in writing about a robot that could kill a human being because it did not understand that it was a robot, and therefore did not apply the Laws of Robotics to its actions.\n\n===Resolving conflicts among the laws===\nAdvanced robots in fiction are typically programmed to handle the Three Laws in a sophisticated manner. In many stories, such as \"[[Runaround (story)|Runaround]]\" by Asimov, the potential and severity of all actions are weighed and a robot will break the laws as little as possible rather than do nothing at all. For example, the First Law may forbid a robot from functioning as a surgeon, as that act may cause damage to a human, however Asimov's stories eventually included robot surgeons (\"The Bicentennial Man\" being a notable example). When robots are sophisticated enough to weigh alternatives, a robot may be programmed to accept the necessity of inflicting damage during surgery in order to prevent the greater harm that would result if the surgery were not carried out, or was carried out by a more fallible human surgeon. In \"[[Evidence (Asimov)|Evidence]]\" [[Susan Calvin]] points out that a robot may even act as a [[Attorney at law (United States)|prosecuting attorney]] because in the American justice system it is the [[jury]] which decides guilt or innocence, the judge who decides the sentence, and the [[executioner]] who carries through [[capital punishment]].<ref name=autogenerated2>{{cite book|title=I, Robot|url=http://nullfile.com/ebooks/%28ebook%29%20Asimov,%20Isaac%20-%20I,%20Robot.pdf|author=Isaac Asimov|accessdate=11 November 2010|page=122|format=Asimov, Isaac - I, Robot.pdf}}</ref>\n\nAsimov's Three Law robots (or Asenion) can experience irreversible mental collapse if they are forced into situations where they cannot obey the First Law, or if they discover they have unknowingly violated it. The first example of this [[failure mode]] occurs in the story \"[[Liar! (short story)|Liar!]]\", which introduced the First Law itself, and introduces failure by dilemma \u2013 in this case the robot will hurt them if he tells them something and hurt them if he does not.<ref name=autogenerated1>{{cite book|title=I, Robot|url=http://nullfile.com/ebooks/%28ebook%29%20Asimov,%20Isaac%20-%20I,%20Robot.pdf|author=Isaac Asimov|accessdate=11 November 2010|page=75|format=Asimov, Isaac - I, Robot.pdf}}</ref> This failure mode, which often ruins the positronic brain beyond repair, plays a significant role in Asimov's SF-mystery novel ''[[The Naked Sun]]''. Here Daneel describes activities contrary to one of the laws, but in support of another, as overloading some circuits in a robot's brain&nbsp;\u2013 the equivalent sensation to pain in humans. The example he uses is forcefully ordering a robot to do a task outside its normal parameters, one that it has been ordered to forgo in favor of a robot specialized to that task.<ref name=\"TNSPain\">{{cite book|last=Asimov|first=Isaac|title=The Naked Sun (ebook)|year=1956\u20131957|page=56|quote=Are you trying to tell me, Daneel, that it hurts the robot to have me do its work? ... experience which the robot undergoes is as upsetting to it as pain is to a human}}</ref> In ''[[Robots and Empire]]'', Daneel states it's very unpleasant for him when making the proper decision takes too long (in robot terms), and he cannot imagine being without the Laws at all except to the extent of it being similar to that unpleasant sensation, only permanent.\n\n==Applications to future technology==\n{{See also|Philosophy of artificial intelligence| Ethics of artificial intelligence|Friendly artificial intelligence}}\n[[File:HONDA ASIMO.jpg|thumb|'''[[ASIMO]]''' is an advanced [[humanoid robot]] developed by [[Honda]]. Shown here at [[Expo 2005]].]]\n\nRobots and artificial intelligences do not inherently contain or obey the Three Laws; their human creators must choose to program them in, and devise a means to do so. Robots already exist (for example, a [[Roomba]]) that are too simple to understand when they are causing pain or injury and know to stop. Many are constructed with physical safeguards such as bumpers, warning beepers, safety cages, or restricted-access zones to prevent accidents. Even the most complex robots currently produced are incapable of understanding and applying the Three Laws; significant advances in artificial intelligence would be needed to do so, and even if AI could reach human-level intelligence, the inherent ethical complexity as well as cultural/contextual dependency of the laws prevent them from being a good candidate to formulate robotics design constraints.<ref>{{cite journal| url=http://www.inf.ufrgs.br/~prestes/Courses/Robotics/beyond%20asimov.pdf | title=Beyond Asimov: The Three Laws of Responsible Robotics | journal=IEEE Intelligent systems| date=July 2009| accessdate = July 2009| issue=4| volume=24|pages=14\u201320| doi=10.1109/mis.2009.69| last1=Murphy | first1=Robin | last2=Woods | first2=David D. }}</ref> However, as the complexity of robots has increased, so has interest in developing guidelines and safeguards for their operation.<ref name=\"moravec\">[[Hans Moravec|Moravec, Hans]]. \"The Age of Robots\", ''Extro 1, Proceedings of the First [[Extropy Institute]] Conference on TransHumanist Thought'' (1994) pp. 84\u2013100. [http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1993/Robot93.html June 1993 version] available online.</ref><ref>{{cite journal| url=http://www.newscientist.com/channel/mech-tech/robots/mg18925445.600-rules-for-the-modern-robot.html | title=Rules for the modern robot| journal=New Scientist| date=27 March 2006| accessdate = 2006-06-12| issue=2544| page=27}}</ref>\n\nIn a 2007 guest editorial in the journal ''[[Science (journal)|Science]]'' on the topic of \"Robot Ethics\", SF author [[Robert J. Sawyer]] argues that since the [[United States Armed Forces|U.S. military]] is a major source of funding for robotic research (and already uses armed [[unmanned aerial vehicles]] to kill enemies) it is unlikely such laws would be built into their designs.<ref name=\"SAWSCI\">{{cite journal| last=Sawyer| first=Robert J.| url=http://sfwriter.com/science.htm| doi=10.1126/science.1151606|journal=Science|date=16 November 2007|title=Guest Editorial: Robot Ethics| accessdate = 2010-10-10| volume=318| issue=5853| page=1037| pmid=18006710}}</ref> In a separate essay, Sawyer generalizes this argument to cover other industries stating:\n\n<blockquote>The development of AI is a business, and businesses are notoriously uninterested in fundamental safeguards \u2014 especially philosophic ones. (A few quick examples: the tobacco industry, the automotive industry, the nuclear industry. Not one of these has said from the outset that fundamental safeguards are necessary, every one of them has resisted externally imposed safeguards, and none has accepted an absolute edict against ever causing harm to humans.)<ref name=\"SAWON3LAWS\">{{cite web| last=Sawyer| first=Robert J.| url=http://www.sfwriter.com/rmasilaw.htm| title=On Asimov's Three Laws of Robotics| year=1991| accessdate = 2006-06-12}}</ref></blockquote>\n\n[[David Langford]] has suggested a tongue-in-cheek set of laws:\n\n#A robot will not harm authorized Government personnel but will [[Terminate with extreme prejudice|terminate intruders with extreme prejudice]].\n#A robot will obey the orders of authorized personnel except where such orders conflict with the Third Law.\n#A robot will guard its own existence with lethal antipersonnel weaponry, because a robot is bloody expensive.\n\nRoger Clarke (aka Rodger Clarke) wrote a pair of papers analyzing the complications in implementing these laws in the event that systems were someday capable of employing them. He argued \"Asimov's Laws of Robotics have been a very successful literary device. Perhaps ironically, or perhaps because it was artistically appropriate, the sum of Asimov's stories disprove the contention that he began with: It is not possible to reliably constrain the behaviour of robots by devising and applying a set of rules.\"<ref>Clarke, Roger. ''Asimov's laws of robotics: Implications for information technology''. [http://csdl.computer.org/comp/mags/co/1993/12/rz053abs.htm Part 1: IEEE Computer, December 1993, p53\u201361.] [http://csdl.computer.org/comp/mags/co/1994/01/r1057abs.htm Part 2: IEEE Computer, Jan 1994, p57\u201366.] Both parts are available without fee at [http://www.rogerclarke.com/SOS/Asimov.html]. Under \"Enhancements to codes of ethics\".</ref> On the other hand, Asimov's later novels ''[[The Robots of Dawn]]'', ''[[Robots and Empire]]'' and ''[[Foundation and Earth]]'' imply that the robots inflicted their worst long-term harm by obeying the Three Laws perfectly well, thereby depriving humanity of inventive or risk-taking behaviour.\n\nIn March 2007 the [[South Korea]]n government announced that later in the year it would issue a \"Robot Ethics Charter\" setting standards for both users and manufacturers. According to Park Hye-Young of the Ministry of Information and Communication the Charter may reflect Asimov's Three Laws, attempting to set ground rules for the future development of robotics.<ref>{{cite news\n| title=Robotic age poses ethical dilemma\n| url=http://news.bbc.co.uk/2/hi/technology/6425927.stm\n| publisher=BBC News\n| date=2007-03-07\n| accessdate=2007-03-07}}</ref>\n\nThe futurist [[Hans Moravec]] (a prominent figure in the [[transhumanism|transhumanist]] movement) proposed that the Laws of Robotics should be adapted to \"corporate intelligences\" \u2014 the [[corporation]]s driven by AI and robotic manufacturing power which Moravec believes will arise in the near future.<ref name=\"moravec\"/> In contrast, the [[David Brin]] novel ''[[Foundation's Triumph]]'' (1999) suggests that the Three Laws may decay into obsolescence: Robots use the Zeroth Law to rationalize away the First Law and robots hide themselves from human beings so that the Second Law never comes into play. Brin even portrays [[R. Daneel Olivaw]] worrying that, should robots continue to reproduce themselves, the Three Laws would become an evolutionary handicap and [[natural selection]] would sweep the Laws away \u2014 Asimov's careful foundation undone by [[evolutionary computation]]. Although the robots would not be evolving through ''design'' instead of ''mutation'' because the robots would have to follow the Three Laws while designing and the prevalence of the laws would be ensured,<ref>{{cite book\n| last = Brin\n| first = David\n| authorlink = David Brin\n| title = Foundation's Triumph\n| year = 1999\n| publisher = HarperCollins\n| isbn = 978-0-06-105241-5}}</ref> design flaws or construction errors could functionally take the place of biological mutation.\n\nIn the July/August 2009 issue of ''IEEE Intelligent Systems'', Robin Murphy (Raytheon Professor of Computer Science and Engineering at Texas A&M) and David D. Woods (director of the Cognitive Systems Engineering Laboratory at Ohio State) proposed \"The Three Laws of Responsible Robotics\" as a way to stimulate discussion about the role of responsibility and authority when designing not only a single robotic platform but the larger system in which the platform operates. The laws are as follows:\n\n# A human may not deploy a robot without the human-robot work system meeting the highest legal and professional standards of safety and ethics.\n# A robot must respond to humans as appropriate for their roles.\n# A robot must be endowed with sufficient situated autonomy to protect its own existence as long as such protection provides smooth transfer of control which does not conflict with the First and Second Laws.<ref name=\"IEEEMWTTLRR\">{{cite web|url=http://researchnews.osu.edu/archive/roblaw.htm |title=Want Responsible Robotics? Start With Responsible Humans |publisher=Researchnews.osu.edu |date= |accessdate=2015-03-28}}</ref>\n\nWoods said, \"Our laws are little more realistic, and therefore a little more boring\u201d and that \"The philosophy has been, \u2018sure, people make mistakes, but robots will be better \u2013 a perfect version of ourselves.\u2019 We wanted to write three new laws to get people thinking about the human-robot relationship in more realistic, grounded ways.\"<ref name=\"IEEEMWTTLRR\"/>\n\nIn October 2013, Alan Winfield suggested at an EUCog meeting<ref>{{cite web|author=Alan Winfield |url=http://alanwinfield.blogspot.co.uk/2013/10/ethical-robots-some-technical-and.html |title=Alan Winfield's Web Log: Ethical Robots: some technical and ethical challenges |publisher=Alanwinfield.blogspot.co.uk |date=2013-10-30 |accessdate=2015-03-28}}</ref> a revised 5 laws that had been published, with commentary, by the EPSRC/AHRC working group in 2010.:<ref>{{cite web|url=http://www.epsrc.ac.uk/research/ourportfolio/themes/engineering/activities/principlesofrobotics/ |title=Principles of robotics - EPSRC website |publisher=Epsrc.ac.uk |date= |accessdate=2015-03-28}}</ref>\n# Robots are multi-use tools. Robots should not be designed solely or primarily to kill or harm humans, except in the interests of national security.\n# Humans, not Robots, are responsible agents. Robots should be designed and operated as far as practicable to comply with existing laws, fundamental rights and freedoms, including privacy. \n# Robots are products. They should be designed using processes which assure their safety and security. \n# Robots are manufactured artefacts. They should not be designed in a deceptive way to exploit vulnerable users; instead their machine nature should be transparent.\n# The person with legal responsibility for a robot should be attributed.\n\n==Other occurrences in media==\n{{Main|The Three Laws of Robotics in popular culture}}\nAsimov himself believed that his Three Laws became the basis for a new view of robots which moved beyond the \"Frankenstein complex\".{{citation needed|date=June 2011}} His view that robots are more than mechanical monsters eventually spread throughout science fiction.{{According to whom|date=June 2011}} Stories written by other authors have depicted robots as if they obeyed the Three Laws but tradition dictates that only Asimov could quote the Laws explicitly.{{According to whom|date=June 2011}} Asimov believed the Three Laws helped foster the rise of stories in which robots are \"lovable\"&nbsp;\u2013 ''[[Star Wars]]'' being his favorite example.<ref>{{cite book| last=Asimov| first=Isaac| year=1995| title=Yours, Isaac Asimov: A Life in Letters|author2=Stanley Asimov | publisher=Doubleday| isbn=0-385-47622-1}}</ref> Where the laws are quoted verbatim, such as in the ''[[Buck Rogers in the 25th Century (TV series)|Buck Rogers in the 25th Century]]'' episode \"Shgoratchx!\", it is not uncommon for Asimov to be mentioned in the same dialogue as can also be seen in the [[Aaron Stone]] pilot where an android states that it functions under Asimov's Three Laws. However, the 1960s German TV series ''[[Raumpatrouille|Raumpatrouille \u2013 Die phantastischen Abenteuer des Raumschiffes Orion]]'' (''Space Patrol \u2013 the Fantastic Adventures of Space Ship Orion'') bases episode three titled \"''H\u00fcter des Gesetzes''\" (\"Guardians of the Law\") on Asimov's Three Laws without mentioning the source.\n\nReferences to the Three Laws have appeared in popular music (\"Robot\" from [[Hawkwind]]'s 1979 album ''[[PXR5]]''), cinema (''[[Repo Man (film)|Repo Man]]'', ''[[Aliens (film)|Aliens]]'', ''[[Ghost in the Shell 2: Innocence]]''), cartoon series (''[[The Simpsons]]''), tabletop roleplaying games ([[Paranoia (role-playing game)|Paranoia]]) and [[webcomics]] (''[[Piled Higher and Deeper]]'' and ''[[Freefall]]'').\n\n===The Three Laws in film===\n[[Robby the Robot]] in ''[[Forbidden Planet]]'' (1956) has a hierarchical command structure which keeps him from harming humans, even when ordered to do so, as such orders cause a conflict and lock-up very much in the manner of Asimov's robots. Robby is one of the first cinematic depictions of a robot with internal safeguards put in place in this fashion. Asimov was delighted with Robby and noted that Robby appeared to be programmed to follow his Three Laws.\n\n[[Image:Bicentennial-man-three-laws.jpg|thumb|NDR-114 explaining the Three Laws]]\nIsaac Asimov's works have been adapted for cinema several times with varying degrees of critical and commercial success. Some of the more notable attempts have involved his \"Robot\" stories, including the Three Laws. The film ''[[Bicentennial Man (film)|Bicentennial Man]]'' (1999) features [[Robin Williams]] as the Three Laws robot NDR-114 (the serial number is partially a reference to [[Stanley Kubrick]]'s [[CRM 114 (device)|signature numeral]]). Williams recites the Three Laws to his employers, the Martin family, aided by a holographic projection. However, the Laws were not the central focus of the film which only loosely follows the original story and has the second half introducing a love interest not present in Asimov's original short story.\n\n[[Harlan Ellison]]'s proposed screenplay for ''[[I, Robot (film)|I, Robot]]'' began by introducing the Three Laws, and issues growing from the Three Laws form a large part of the screenplay's plot development. This is only natural since Ellison's screenplay is one inspired by ''[[Citizen Kane]]'': a frame story surrounding four of Asimov's short-story plots and three taken from the book ''[[I, Robot]]'' itself. Ellison's adaptations of these four stories are relatively faithful although he magnifies [[Susan Calvin]]'s role in two of them. Due to various complications in the Hollywood moviemaking system, to which Ellison's introduction devotes much invective, his screenplay was never filmed.<ref>{{cite book| last=Ellison| first=Harlan| title=I, Robot: The illustrated screenplay| publisher=Aspect| year=1994| isbn=0-446-67062-6}}</ref>\n\nIn the 1986 movie [[Aliens (film)|''Aliens'']], in a scene after the android [[List of Alien characters|Bishop]] accidentally cuts himself during the [[knife game]], he attempts to reassure [[Ellen Ripley|Ripley]] by stating that: \"It is impossible for me to harm or by omission of action, allow to be harmed, a human being\".<ref>{{cite web|url=http://www.imdb.com/title/tt0090605/quotes|title= Aliens (1986) - Memorable quotes|publisher=IMDb.com|accessdate=2015-03-28}}</ref> By contrast, in the 1979 movie from the same series, ''[[Alien (film)|Alien]]'', the human crew of a starship infiltrated by a hostile alien are informed by the android [[Alien (film)#Ash|Ash]] that his instructions are: \"Return alien life form, all other priorities rescinded\",<ref>{{cite web|url=http://www.angelfire.com/oh/quotations/movies/a/alien.html |title=ALIEN |publisher=Angelfire.com |date= |accessdate=2015-03-28}}</ref> illustrating how the laws governing behaviour around human safety can be rescinded by Executive Order.\n\nIn the 1987 film ''[[RoboCop]]'' and its sequels, the partially human main character has been programmed with three \"prime directives\" that he must obey without question. Even if different in letter and spirit they have some similarities with Asimov's Three Laws. They are:<ref name=\"AARobocop\">{{cite book|title=Alternate Americas: science fiction film and American culture|year=2006|publisher=Greenwood Publishing Group|isbn=978-0-275-98395-6|url=https://books.google.com/books?id=CVvb6gfT4o4C&pg=PA205&dq=robocop+three+laws#v=onepage&q=robocop%20three%20laws&f=false|author=M. Keith Booker|accessdate=11 November 2010|page=205|quote=In a variation on Isaac Asimov's famous Three Laws of Robotics ...}}</ref>\n\n#'''Serve the Public Trust'''\n#'''Protect the Innocent''' \n#'''Uphold the Law'''\n#'''Classified'''\n\nThese particular laws allow Robocop to harm a human being in order to protect another human, fulfilling his role as would a human law enforcement officer. The classified fourth directive is one that forbids him from harming any OCP employee, as OCP had created him, and this command overrides the others, meaning that he could not cause harm to an employee even in order to protect others.\n\nThe plot of the film released in 2004 under the name, ''[[I, Robot (film)|I, Robot]]'' is \"suggested by\" Asimov's robot fiction stories<ref>\"Suggested by\" Isaac Asimov's robot stories\u2014two stops removed from \"based on\" and \"inspired by\", the credit implies something scribbled on a bar napkin\u2014[[Alex Proyas]]' science-fiction thriller ''I, Robot'' sprinkles Asimov's ideas like seasoning on a giant bucket of popcorn. [...] Asimov's simple and seemingly foolproof Laws of Robotics, designed to protect human beings and robots alike from harm, are subject to loopholes that the author loved to exploit. After all, much of humanity agrees in principle to abide by the [[Ten Commandments]], but [[free will]], circumstance, and contradictory impulses can find wiggle room in even the most unambiguous decree. Whenever ''I, Robot'' pauses between action beats, Proyas captures some of the excitement of movies like ''[[The Matrix]]'', ''[[Minority Report (film)|Minority Report]]'', and ''[[A.I. (film)|A.I.]]'', all of which proved that philosophy and social commentary could be smuggled into spectacle. Had the film been based on Asimov's stories, rather than merely \"suggested by\" them, Proyas might have achieved the intellectual heft missing from his stylish 1998 [[cult film|cult]] favorite ''[[Dark City (1998 film)|Dark City]].''\n{{cite web\n| last=Tobias\n| first= Scott\n| publisher=[[The Onion|The Onion A.V. Club]]\n| url=http://avclub.com/content/node/17881\n| title=review of I, Robot\n| date=20 July 2004\n| accessdate = 2006-06-12}}\n</ref>\nand advertising for the film included a trailer featuring the Three Laws followed by the [[aphorism]], \"Rules were made to be broken\". The film opens with a recitation of the Three Laws and explores the implications of the [[#Zeroth Law added|Zeroth Law]] as a logical extrapolation. The major conflict of the film comes from a computer artificial intelligence, similar to the hivemind world Gaia in the [[Foundation series|''Foundation'' series]], reaching the conclusion that humanity is incapable of taking care of itself.<ref name=\"BBCIrobot\">{{cite news|title=A fresh prince in a robot's world|url=http://news.bbc.co.uk/1/hi/entertainment/3533118.stm|publisher=BBC News|accessdate=11 November 2010|first=Stephen|last=Dowling|date=4 August 2004}}</ref>\n\n== See also ==\n{{Portal|Ethics|Robotics|Speculative fiction}}\n* [[Roboethics]]\n* [[Ethics of artificial intelligence]]\n* [[Tilden's Law of Robotics]]\n* [[Friendly artificial intelligence|Friendliness Theory]] \u2013 a theory which states that, rather than using \"Laws\", intelligent machines should be programmed to be inherently [[altruistic]], and then to use their own best judgement in how to carry out this altruism, thus sidestepping the problem of how to account for a vast number of unforeseeable eventualities.\n* [[Military robot]]s which may be designed such that they violate Asimov's First Law.\n* [[Three Laws of Transhumanism]]\n\n==References==\n\n===Bibliography===\n*Asimov, Isaac (1979). ''In Memory Yet Green''. Doubleday. ISBN 0-380-75432-0.\n*Asimov, Isaac (1964). \"Introduction\". ''The Rest of the Robots''. Doubleday. ISBN 0-385-09041-2.\n*James Gunn. (1982). ''Isaac Asimov: The Foundations of Science Fiction''. Oxford u.a.: Oxford Univ. Pr.. ISBN 0-19-503060-5.\n*Patrouch, Joseph F. (1974). ''The Science Fiction of Isaac Asimov''. Doubleday. ISBN 0-385-08696-2.\n\n==References==\n{{Reflist|colwidth=30em}}\n\n==External links==\n{{Spoken Wikipedia|Three_Laws_Audio.ogg|2008-11-28}}\n*Worley, Gordon. \"[http://www.asimovlaws.com/articles/archives/2004/07/robot_oppressio_1.html Robot Oppression: Unethicality of the Three Laws]\".\n*\"[http://www.asimovonline.com/asimov_FAQ.html#non-literary12 Frequently Asked Questions about Isaac Asimov]\", ''AsimovOnline'' 27 September 2004.\n*[http://www.inl.gov/adaptiverobotics/humanoidrobotics/ethicalconsiderations.shtml Ethical Considerations for Humanoid Robots: Why Asimov's Three Laws are not enough].\n*[http://www.physorg.com/news164887377.html Living Safely with Robots, Beyond Asimov's Laws], ''PhysOrg.com'', June 22, 2009.\n*[http://works.bepress.com/weng_yueh_hsuan/3/ Safety Intelligence and Legal Machine Language: Do we need the Three Laws of Robotics?], ''Vienna: I-Tech'', August 2008.\n\n{{Robot series}}\n{{Robotics}}\n\n[[Category:Fictional laws]]\n[[Category:Foundation universe]]\n[[Category:Isaac Asimov]]\n[[Category:Laws of robotics]]\n[[Category:Technology folklore]]\n[[Category:Robots in literature]]\n[[Category:1942 introductions]]"}]}}}}