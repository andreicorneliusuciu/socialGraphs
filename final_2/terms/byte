{"batchcomplete":"","query":{"normalized":[{"from":"byte","to":"Byte"}],"pages":{"3365":{"pageid":3365,"ns":0,"title":"Byte","revisions":[{"contentformat":"text/x-wiki","contentmodel":"wikitext","*":"{{hatnote|This article is about the unit of information. For other uses, see [[Byte (disambiguation)]].}}\n\nThe '''byte''' ({{IPAc-en|\u02c8|b|a\u026a|t}}) is a [[units of information|unit of digital information]] that most commonly consists of eight [[bit]]s. Historically, the byte (symbol '''B''') was the number of bits used to encode a single [[character (computing)|character]] of text in a computer<!--\n--><ref name = Bemer1962>{{citation\n|url=http://archive.computerhistory.org/resources/text/IBM/Stretch/pdfs/Buchholz_102636426.pdf\n|title=Planning a Computer System \u2013 Project Stretch\n| first1 = RW | last1 = Bemer | first2 = Werner | last2 = Buchholz\n| editor-first = Werner | editor-last = Buchholz\n|year=1962 | chapter = 4, Natural Data Units | format = PDF | pages= 39\u201340 }}</ref><!--\n--><ref>{{citation\n| first = RW \n| last = Bemer \n| title = A proposal for a generalized card code of 256 characters \n| journal = Communications of the ACM | volume = 2 | number = 9 | pages = 19\u201323 | year = 1959 \n| doi=10.1145/368424.368435}}</ref> \nand for this reason it is the smallest [[address space|addressable]] unit of [[Computer memory|memory]] in many [[computer architecture]]s.\nThe size of the byte has historically been hardware dependent and no definitive standards existed that mandated the size. The [[de facto standard|''de facto'' standard]] of eight bits is a convenient [[power of two]] permitting the values 0 through 255 for one byte.  The international standard [[IEC 80000-13]] codified this common meaning. Many types of applications use information representable in eight or fewer bits and processor designers optimize for this common usage. The popularity of major commercial computing architectures has aided in the ubiquitous acceptance of the 8-bit size.<ref>{{cite web|url=http://www.computerhistory.org/internet_history/#1964|title=Computer History Museum - Exhibits - Internet History - 1964|publisher = Computer History Museum}}</ref>\n\n==History==\nThe term ''byte'' was coined by [[Werner Buchholz]] in July 1956, during the early design phase for the [[IBM 7030|IBM Stretch]]<ref>{{cite web | url = http://archive.computerhistory.org/resources/text/IBM/Stretch/102636400.txt|title= Timeline of the IBM Stretch/Harvest era (1956\u20131961) | publisher = Computer History | date=July 1956|author=Werner Buchholz}}</ref><ref>{{cite web|url=http://catb.org/~esr/jargon/html/B/byte.html|title=byte definition}}</ref> computer, which had addressing to the bit and variable field length (VFL) instructions with a byte size encoded in the instruction.\nIt is a deliberate respelling of ''bite'' to avoid accidental mutation to ''bit''.<ref name=Bemer1962/>\n\nEarly computers used a variety of four-bit [[binary coded decimal]] (BCD) representations and the [[Sixbit|six-bit]] codes for printable graphic patterns common in the [[U.S. Army]] ([[Fieldata]]) and Navy. These representations included alphanumeric characters and special graphical symbols. These sets were expanded in 1963 to seven bits of coding, called the [[ASCII|American Standard Code for Information Interchange]] (ASCII) as the [[Federal Information Processing Standard]], which replaced the incompatible teleprinter codes in use by different branches of the U.S. government and universities during the 1960s. ASCII included the distinction of upper- and lowercase alphabets and a set of [[control character]]s to facilitate the transmission of written language as well as printing device functions, such as page advance and line feed, and the physical or logical control of data flow over the transmission media. During the early 1960s, while also active in ASCII standardization, IBM simultaneously introduced in its product line of [[System/360]] the eight-bit [[Extended Binary Coded Decimal Interchange Code]] (EBCDIC), an expansion of their [[BCD (6-bit)|six-bit binary-coded decimal (BCDIC)]] representation used in earlier card punches.<ref name=\"ibmebcdic\">{{cite web\n |url=http://publib.boulder.ibm.com/infocenter/zos/v1r9/index.jsp?topic=/com.ibm.zos.r9.adms700/adms7a05158.htm \n |title=IBM confirms the use of EBCDIC in their mainframes as a default practice \n |year=2008 \n |accessdate=2008-06-16 \n |publisher=IBM \n}}{{dead link|date=November 2016 |bot=InternetArchiveBot |fix-attempted=yes }}</ref>\nThe prominence of the System/360 led to the ubiquitous adoption of the eight-bit storage size, while in detail the EBCDIC and ASCII encoding schemes are different.\n\nIn the early 1960s, AT&T introduced [[digital telephony]] first on long-distance [[trunk line]]s.  These used the eight-bit [[\u00b5-law algorithm|\u00b5-law encoding]].  This large investment promised to reduce transmission costs for eight-bit data.\n\nThe development of [[eight-bit]] [[microprocessor]]s in the 1970s popularized this storage size. Microprocessors such as the [[Intel 8008]], the direct predecessor of  the [[Intel 8080|8080]] and the [[Intel 8086|8086]], used in early personal computers, could also perform a small number of operations on the [[4bit|four-bit]] pairs in a byte, such as the decimal-add-adjust (DAA) instruction. A four-bit quantity is often called a [[nibble]], also ''nybble'', which is conveniently represented by a single [[hexadecimal]] digit.\n\nThe term ''[[Octet (computing)|octet]]'' is used to unambiguously specify a size of eight bits. It is used extensively in [[Protocol (computing)|protocol]] definitions.\n\nHistorically, the term ''octad'' or ''octade'' was used to denote eight bits as well at least in Western Europe;<ref name=\"Williams_1969\"/><ref name=\"Philips_1971\"/> however, this usage is no longer common. The exact origin of the term is unclear, but it can be found in British, Dutch, and German sources of the 1960s and 1970s, and throughout the documentation of [[Philips]] mainframe computers.\n\n==Unit symbol==\n{{Bit and byte prefixes}}\nThe unit symbol for the byte is specified in IEC 80000-13, [[IEEE 1541]] and the Metric Interchange Format<ref name=\"Metric-Interchange-Format\">[http://people.csail.mit.edu/jaffer/MIXF Metric-Interchange-Format]</ref> as the upper-case character B. The unit symbol kB is commonly used for [[kilobyte]], but may be confused with the still often-used abbreviation of kb for [[kilobit]]. IEEE 1541 specifies the lower case character b as the symbol for [[bit]]; however, IEC 80000-13 and Metric-Interchange-Format specify the symbol as bit, e.g., Mbit (megabit), providing disambiguation from B for byte.\n\nA byte is symbolically marked as the upper-case '''B''' by the IEC and IEEE<ref name=\"Metric-Interchange-Format\"/> in contrast to the bit, whose IEEE symbol is a lower-case b (whereas IEC distinguishes further by using the symbol 'bit').  Internationally, the unit ''[[Octet (computing)|octet]]'', symbol o, explicitly denotes a sequence of eight bits, eliminating the ambiguity of the byte.<ref>{{cite web|url=http://www.tcpipguide.com/free/t_BinaryInformationandRepresentationBitsBytesNibbles-3.htm|title=The TCP/IP Guide - Binary Information and Representation}}</ref> The usage of the term ''octad(e)'' for eight bits is no longer common.<ref name=\"Williams_1969\">{{cite web|title=British Commercial Computer Digest: Pergamon Computer Data Series|first=R. H.|last=Williams|publisher=Pergamon Press|date=1969-01-01|isbn=1483122107|id=978-1483122106|url=http://www.amazon.de/British-Commercial-Computer-Digest-Pergamon/dp/1483122107|accessdate=2015-08-03}}</ref><ref name=\"Philips_1971\">{{cite web|title=Philips - Philips Data Systems' product range - April 1971|publisher=Philips|date=1971|url=http://www.intact-reunies.nl/pdf/product1971.pdf|accessdate=2015-08-03}}</ref>\n\nThere is an ambiguity in the [[International System of Quantities]], where the unit represented by the B symbol can be either the bel or the byte. In that system, the unit represented (bel) quantifies logarithmic power ratios; in contrast to the byte represented in the IEC specification. However, there is little danger of confusion, because the unprefixed bel is a rarely used unit. It is used primarily in its decadic fraction, the [[decibel]] (dB), for [[signal strength]] and [[sound pressure level]] measurements. The decibyte (represented value one tenth of a byte) shares the same d- fractional prefix for one tenth of the unit, but by comparison would only be used in derived units &ndash; for example the time-derived [[transmission rate]].\n\nThe lowercase letter o for [[Octet (computing)|octet]] is defined as the symbol for octet in IEC 80000-13 and is commonly used in languages such as [[French language|French]]<ref>{{cite web |url=http://www.iec.ch/si/binary.htm|title=When is a kilobyte a kibibyte? And an MB an MiB? | date= |work=The International System of Units and the IEC |publisher=[[International Electrotechnical Commission]] |accessdate=August 30, 2010}})</ref> and [[Romanian language|Romanian]], and is also combined with metric prefixes for multiples, for example ko and Mo.\n\n==Unit multiples==\n[[File:Binaryvdecimal.svg|thumb|right|275px|Percentage difference between decimal and binary interpretations of the unit prefixes grows with increasing storage size]]\n\nDespite standardization efforts, ambiguity still exists in the meanings of the [[SI prefix|SI (or metric) prefixes]] used with the unit byte, especially concerning the prefixes ''kilo'' (k or K), ''mega'' (M), and ''giga'' (G). Computer memory has a binary architecture in which multiples are expressed in [[power of two|powers of 2]]. In some fields of the software and computer hardware industries a [[binary prefix]] is used for bytes and bits, while producers of computer storage devices practice adherence to decimal SI multiples. For example, a computer disk drive capacity of 100&nbsp;gigabytes is specified when the disk contains 100 billion bytes (93&nbsp;gibibytes) of storage space.{{citation needed|reason=Memory uses a binary prefix.|date=September 2016}}\n\nWhile the numerical difference between the decimal and binary interpretations is relatively small for the prefixes [[Kilo-|kilo]] and [[Mega-|mega]], it grows to over 20% for prefix [[yotta]]. The linear-log graph at right illustrates the difference versus storage size up to an [[exa]]byte.\n\n==Common uses==\nMany [[programming language]]s defined the [[data type]] ''byte''.\n\nThe [[C (programming language)|C]] and [[C++]] programming languages define ''byte'' as an \"''addressable unit of data storage large enough to hold any member of the basic character set of the execution environment''\" (clause 3.6 of the C standard). The C standard requires that the integral data type ''unsigned char'' must hold at least 256 different values, and is represented by at least eight bits (clause 5.2.4.2.1). Various implementations of C and C++ reserve 8, 9, 16, 32, or 36 bits for the storage of a byte.<ref>\nMarshall Cline.\n[https://isocpp.org/wiki/faq/intrinsic-types#very-large-bytes \"I could imagine a machine with 9-bit bytes. But surely not 16-bit bytes or 32-bit bytes, right?\"]\n</ref><ref>\n{{Citation\n| last       = Klein\n| first      = Jack\n| year       = 2008\n| title      = Integer Types In C and C++\n| url        = http://home.att.net/~jackklein/c/inttypes.html#char\n| archive-url = https://web.archive.org/web/20100327225121/http://home.att.net/~jackklein/c/inttypes.html#char\n| archive-date = 2010-03-27\n| accessdate = 2015-06-18\n}}\n</ref>{{efn|The actual number of bits in a particular implementation is documented as <code>CHAR_BIT</code> as implemented in the file [[limits.h]].}} In addition, the C and C++ standards require that there are no \"gaps\" between two bytes. This means every bit in memory is part of a byte.<ref>\nMarshall Cline.\n[https://isocpp.org/wiki/faq/intrinsic-types#bytes-review \"C++ FAQ: the rules about bytes, chars, and characters\"].\n</ref>\n\n[[Java (programming language)|Java's]] primitive <code>byte</code> data type is always defined as consisting of 8 bits and being a signed data type, holding values from \u2212128 to 127.\n\n.NET programming languages, such as C#, define both an unsigned <code>byte</code> and a signed <code>sbyte</code>, holding values from 0 to 255, and \u2212128 to 127, respectively.\n\nIn data transmission systems, the byte is defined as a contiguous sequence of bits in a serial data stream, representing is the smallest distinguished unit of data. A transmission unit might include start bits, stop bits, or [[parity bit]]s, and thus could vary from 7 to 12 bits to contain a single 7-bit [[ASCII]] code.<ref>\nNorthwestern University.\n[http://www.ece.northwestern.edu/local-apps/matlabhelp/techdoc/matlab_external/ch_seri8.html \"External Interfaces/API\"]\n</ref>\n\n==See also==\n* [[Word (computer architecture)]]\n* [[Data hierarchy]]\n* [[JBOB]], Just a Bunch Of Bytes\n* [[Primitive data type]]\n* [[Tryte]]\n* [[Qubyte]] (quantum byte)\n\n==Notes==\n{{notelist}}\n\n==References==\n{{reflist|30em}}\n{{refimprove|date=June 2011}}\n\n{{Computer Storage Volumes}}\n{{Data types}}\n\n[[Category:Data types]]\n[[Category:Units of information]]\n[[Category:Computer memory]]\n[[Category:Data unit]]\n[[Category:Primitive types]]\n[[Category:Words coined in the 1950s]]"}]}}}}