{"batchcomplete":"","query":{"normalized":[{"from":"Machine_code","to":"Machine code"}],"pages":{"20683":{"pageid":20683,"ns":0,"title":"Machine code","revisions":[{"contentformat":"text/x-wiki","contentmodel":"wikitext","*":"{{Program execution}}\n[[File:W65C816S Machine Code Monitor.jpeg|thumb|Machine language monitor in a [[W65C816S]] [[single-board computer]], displaying [[disassembler|code disassembly]], as well as processor register and memory dumps.]]\n'''Machine code''' or '''machine language''' is a set of [[instruction set|instructions]] executed directly by a [[computer]]'s [[central processing unit]] (CPU). Each instruction performs a very specific task, such as a load, a [[jump instruction|jump]], or an [[Arithmetic logic unit|ALU]] operation on a unit of data in a [[processor register|CPU register]] or memory. Every program directly executed by a CPU is made up of a series of such instructions.\n\nNumerical machine code (i.e., not [[assembly code]]) may be regarded as the lowest-level representation of a [[Compiler|compiled]] or [[assembly language|assembled]] [[computer program]] or as a primitive and [[computer hardware|hardware]]-dependent [[programming language]]. While it is possible to write programs directly in numerical machine code, it is tedious and error prone to manage individual bits and calculate numerical addresses and constants manually. For this reason machine code is almost never used to write programs.\n\nAlmost all practical programs today are written in higher-level languages or [[assembly language]]. The [[source code]] is then translated to executable machine code by utilities such as [[compiler]]s, [[assembler (computing)|assemblers]], and [[Linker (computing)|linkers]], with the important exception of [[interpreted language|interpreted]] programs,<ref>Such as many versions of [[BASIC]], especially early ones, as well as [[Smalltalk]], [[MATLAB]], [[Perl (programming language)|Perl]], [[Python (programming language)|Python]], [[Ruby (programming language)|Ruby]] and other special purpose or [[scripting language]]s.</ref> which are not translated into machine code. However, the ''[[interpreter (computing)|interpreter]]'' itself, which may be seen as an executor or processor, performing the instructions of the source code, typically consists of directly executable machine code (generated from assembly or high level language source code).\n\n==Machine code instructions==\n{{main |Instruction set}}\nEvery processor or [[processor family]] has its own machine code [[instruction set]]. Instructions are patterns of [[bit]]s that by physical design correspond to different commands to the machine. Thus, the instruction set is specific to a class of processors using (mostly) the same architecture. Successor or derivative processor designs often include all the instructions of a predecessor and may add additional instructions. Occasionally, a successor design will discontinue or alter the meaning of some instruction code (typically because it is needed for new purposes), affecting code compatibility to some extent; even nearly completely compatible processors may show slightly different behavior for some instructions, but this is rarely a problem. Systems may also differ in other details, such as memory arrangement, [[operating system]]s, or [[Peripheral|peripheral devices]]. Because a program normally relies on such factors, different systems will typically not run the same machine code, even when the same type of processor is used.\n\nA machine code instruction set may have all instructions of the same length, or it may have variable-length instructions. How the patterns are organized varies strongly with the particular architecture and often also with the type of instruction. Most instructions have one or more [[opcode]] fields which specifies the basic instruction type (such as arithmetic, logical, [[Branch (computer science)|jump]], etc.) and the actual operation (such as add or compare) and other fields that may give the type of the [[operand]](s), the [[addressing mode]](s), the addressing offset(s) or index, or the actual value itself (such constant operands contained in an instruction are called ''immediates'').<ref>{{cite web|url=http://programmedlessons.org/AssemblyTutorial/Chapter-11/ass11_2.html|title=Immediate Operand|author=Bradley Kjell; kjell at ieee dot org|publisher=}}</ref>\n\nNot all machines or individual instructions have explicit operands. An [[accumulator machine]] has a combined left operand and result in an implicit accumulator for most arithmetic instructions. Other architectures (such as 8086 and the x86-family) have accumulator versions of common instructions, with the accumulator regarded as one of the general registers by longer instructions. A [[stack machine]] has most or all of its operands on an implicit stack. Special purpose instructions also often lack explicit operands (CPUID in the x86 architecture writes values into four implicit destination registers, for instance). This distinction between explicit and implicit operands is important in machine code generators, especially in the register allocation and live range tracking parts. A good code optimizer can track implicit as well as explicit operands which may allow more frequent [[constant propagation]], [[constant folding]] of registers (a register assigned the result of a constant expression freed up by replacing it by that constant) and other code enhancements.\n\n==Programs==\nA computer program is a sequence of instructions that are executed by a CPU.  While simple processors execute instructions one after another, [[superscalar]] processors are capable of executing several instructions at once.\n\n[[Program flow]] may be influenced by special 'jump' instructions that transfer execution to an instruction other than the numerically following one. [[Conditional branch|Conditional jump]]s are taken (execution continues at another address) or not (execution continues at the next instruction) depending on some condition.\n\n==Assembly languages==\n{{main|Assembly language}}\nA much more readable rendition of machine language, called [[assembly language]], uses [[Assembly language#Opcode mnemonics and extended mnemonics|mnemonic code]]s to refer to machine code instructions, rather than using the instructions' numeric values directly. For example, on the [[Zilog Z80]] processor, the machine code <code>00000101</code>, which causes the CPU to decrement the <code>B</code> [[processor register]], would be represented in assembly language as <code>DEC B</code>.\n\n==Example==\nThe [[MIPS instruction set]] provides a specific example for a machine code whose instructions are always 32 bits long. The general type of instruction is given by the ''op'' (operation) field, the highest 6 bits. J-type (jump) and I-type (immediate) instructions are fully specified by ''op''. R-type (register) instructions include an additional field ''funct'' to determine the exact operation. The fields used in these types are:\n\n    6      5     5     5     5      6 bits\n [  op  |  rs |  rt |  rd |shamt| funct]  R-type\n [  op  |  rs |  rt | address/immediate]  I-type\n [  op  |        target address        ]  J-type\n\n''rs'', ''rt'', and ''rd'' indicate register operands; ''shamt'' gives a shift amount; and the ''address'' or ''immediate'' fields contain an operand directly.\n\nFor example, adding the registers 1 and 2 and placing the result in register 6 is encoded:\n\n [  op  |  rs |  rt |  rd |shamt| funct]\n     0     1     2     6     0     32     decimal\n  000000 00001 00010 00110 00000 100000   binary\n\nLoad a value into register 8, taken from the memory cell 68 cells after the location listed in register 3:\n\n [  op  |  rs |  rt | address/immediate]\n    35     3     8           68           decimal\n  100011 00011 01000 00000 00001 000100   binary\n\nJumping to the address 1024:\n\n [  op  |        target address        ]\n     2                 1024               decimal\n  000010 00000 00000 00000 10000 000000   binary\n\n==Relationship to microcode==\nIn some [[computer architecture]]s, the machine code is implemented by a more fundamental underlying layer of programs called [[microprogram]]s, providing a common machine language interface across a line or family of different models of computer with widely different underlying [[dataflow]]s. This is done to facilitate [[porting]] of machine language programs between different models. An example of this use is the IBM [[System/360]] family of computers and their successors. With dataflow path widths of 8 bits to 64 bits and beyond, they nevertheless present a common architecture at the machine language level across the entire line.\n\nUsing a [[microcode]] layer to implement an [[emulator]] enables the computer to present the architecture of an entirely different computer. The System/360 line used this to allow porting programs from earlier IBM machines to the new family of computers, e.g. an [[IBM 1400 series|IBM 1401/1440/1460]] emulator on the IBM S/360 model 40.\n\n==Relationship to bytecode==\nMachine code should not be confused with so-called \"[[bytecode]]\" (or the older term [[p-code machine|p-code]]), which is either executed by an interpreter or itself compiled into machine code for faster (direct) execution. Machine code and assembly code are sometimes called ''[[native (computing)|native]] code'' when referring to platform-dependent parts of language features or libraries.<ref>{{cite web|title=Managed, Unmanaged, Native: What Kind of Code Is This?|url=http://www.developer.com/net/cplus/article.php/2197621/Managed-Unmanaged-Native-What-Kind-of-Code-Is-This.htm|publisher=''developer.com''|accessdate=2008-09-02}}</ref>\n\n==Storing in memory==\nThe [[Harvard architecture]] is a computer architecture with physically separate storage and signal pathways for the code (instructions) and [[data (computing)|data]]. Today, most processors implement such separate signal pathways for performance reasons but actually implement a [[Modified Harvard architecture]],{{Citation needed|date=March 2014}} so they can support tasks like loading an [[executable]] program from [[data storage device|disk storage]] as data and then executing it. Harvard architecture is contrasted to the [[Von Neumann architecture]], where data and code are stored in the same memory which is read by the processor allowing the computer to execute commands.\n\nFrom the point of view of a [[process (computing)|process]], the ''code space'' is the part of its [[virtual address space|address space]] where the code in execution is stored. In [[computer multitasking|multitasking]] systems this comprises the program's [[code segment]] and usually [[shared libraries]]. In [[Thread (computing)|multi-threading]] environment, different threads of one process share code space along with data space, which reduces the overhead of [[context switching]] considerably as compared to process switching.\n\n==Readability by humans==\nIt has been said that machine code is so unreadable that the [[United States Copyright Office]] cannot identify whether a particular encoded program is an original work of authorship;<ref>{{Cite journal|title=CONTU Revisited: The Case against Copyright Protection for Computer Programs in Machine-Readable Form|author=Pamela Samuelson|publisher=Duke Law Journal|volume=1984|date=Sep 1984|pages=663\u2013769|jstor=1372418|issue=4|postscript=.}}</ref> however, the US Copyright Office ''does'' allow for copyright registration of computer programs.<ref>{{cite web|url=http://www.copyright.gov/circs/circ61.pdf|title=Copyright Registration for Computer Programs|publisher=US Copyright Office|date=August 2008|accessdate=February 23, 2014}}</ref> [[Douglas Hofstadter]] compares machine code with the [[genetic code]]: \"Looking at a program written in machine language is vaguely comparable to looking at a [[DNA]] molecule atom by atom.\"<ref>{{Cite journal|author=D. Hofstadter|title=G\u00f6del, Escher, Bach: An Eternal Golden Braid|page=290|year=1980|postscript=.}}</ref>\n\n==See also==\n{{Wiktionary|machine code}}\n* [[Assembly language]]\n* [[Endianness]]\n* [[List of programming languages by type#Machine languages|List of machine languages]]\n* [[Machine code monitor]]\n* [[Overhead code]]\n* [[P-code machine]]\n* [[Reduced instruction set computing]] (RISC)\n* [[Very long instruction word]]\n* Teaching Machine Code: [[Micro-Professor MPF-I]]\n\n==Notes and references==\n{{reflist}}\n\n==Further reading==\n* {{cite book\n | first = John L.\n | last = Hennessy\n | authorlink = John L. Hennessy\n |author2=Patterson, David A. |authorlink2=David A. Patterson (scientist)\n | title = Computer Organization and Design. The Hardware/Software Interface.\n | publisher = Morgan Kaufmann Publishers\n | isbn = 1-55860-281-X\n}}\n* {{cite book\n | first = Andrew S.\n | last = Tanenbaum\n | authorlink = Andrew S. Tanenbaum\n | title = Structured Computer Organization\n | publisher = Prentice Hall\n | isbn = 0-13-020435-8\n}}\n* {{cite book\n | first = J. Glenn\n | last = Brookshear\n | title = Computer Science: An Overview\n | publisher = Addison Wesley\n | isbn = 0-321-38701-5\n}}\n\n{{Application binary interface}}\n{{Programming language}}\n\n{{Authority control}}\n\n[[Category:Assembly languages|*]]\n[[Category:Machine code|*]]"}]}}}}